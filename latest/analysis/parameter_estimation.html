<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Parameter Estimation · DifferentialEquations.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/highlightjs/default.css" rel="stylesheet" type="text/css"/><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../index.html"><img class="logo" src="../assets/logo.png" alt="DifferentialEquations.jl logo"/></a><h1>DifferentialEquations.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" action="../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../index.html">Home</a></li><li><span class="toctext">Tutorials</span><ul><li><a class="toctext" href="../tutorials/ode_example.html">Ordinary Differential Equations</a></li><li><a class="toctext" href="../tutorials/sde_example.html">Stochastic Differential Equations</a></li><li><a class="toctext" href="../tutorials/rode_example.html">Random Ordinary Differential Equations</a></li><li><a class="toctext" href="../tutorials/dde_example.html">Delay Differential Equations</a></li><li><a class="toctext" href="../tutorials/dae_example.html">Differential Algebraic Equations</a></li><li><a class="toctext" href="../tutorials/discrete_stochastic_example.html">Discrete Stochastic (Gillespie) Equations</a></li><li><a class="toctext" href="../tutorials/jump_diffusion.html">Jump Diffusion Equations</a></li><li><a class="toctext" href="../tutorials/fempoisson_example.html">Poisson Equation Finite Element Method</a></li><li><a class="toctext" href="../tutorials/femheat_example.html">Heat Equation Finite Element Method</a></li><li><a class="toctext" href="../tutorials/femstochastic_example.html">Stochastic Finite Element Method</a></li></ul></li><li><span class="toctext">Basics</span><ul><li><a class="toctext" href="../basics/overview.html">Overview of DifferentialEquations.jl</a></li><li><a class="toctext" href="../basics/common_solver_opts.html">Common Solver Options</a></li><li><a class="toctext" href="../basics/solution.html">Solution Handling</a></li><li><a class="toctext" href="../basics/plot.html">Plot Functions</a></li><li><a class="toctext" href="../basics/integrator.html">Integrator Interface</a></li><li><a class="toctext" href="../basics/compatibility_chart.html">Solver Compatibility Chart</a></li></ul></li><li><span class="toctext">Problem Types</span><ul><li><a class="toctext" href="../types/discrete_types.html">Discrete Problems</a></li><li><a class="toctext" href="../types/ode_types.html">ODE Problems</a></li><li><a class="toctext" href="../types/steady_state_types.html">Steady State Problems</a></li><li><a class="toctext" href="../types/sde_types.html">SDE Problems</a></li><li><a class="toctext" href="../types/rode_types.html">RODE Problems</a></li><li><a class="toctext" href="../types/dde_types.html">DDE Problems</a></li><li><a class="toctext" href="../types/dae_types.html">DAE Problems</a></li><li><a class="toctext" href="../types/jump_types.html">Jump Problems</a></li><li><a class="toctext" href="../types/fem_types.html">FEM Problems</a></li></ul></li><li><span class="toctext">Solver Algorithms</span><ul><li><a class="toctext" href="../solvers/discrete_solve.html">Discrete Solvers</a></li><li><a class="toctext" href="../solvers/ode_solve.html">ODE Solvers</a></li><li><a class="toctext" href="../solvers/refined_ode_solve.html">Refined ODE Solvers</a></li><li><a class="toctext" href="../solvers/steady_state_solve.html">Steady State Solvers</a></li><li><a class="toctext" href="../solvers/sde_solve.html">SDE Solvers</a></li><li><a class="toctext" href="../solvers/rode_solve.html">RODE Solvers</a></li><li><a class="toctext" href="../solvers/dde_solve.html">DDE Solvers</a></li><li><a class="toctext" href="../solvers/dae_solve.html">DAE Solvers</a></li><li><a class="toctext" href="../solvers/fempoisson_solve.html">FEM Poisson Solvers</a></li><li><a class="toctext" href="../solvers/femheat_solve.html">FEM Heat Solvers</a></li></ul></li><li><span class="toctext">Additional Features</span><ul><li><a class="toctext" href="../features/performance_overloads.html">Performance Overloads</a></li><li><a class="toctext" href="../features/diffeq_arrays.html">DiffEq-Specific Array Types</a></li><li><a class="toctext" href="../features/noise_process.html">Noise Processes</a></li><li><a class="toctext" href="../features/linear_nonlinear.html">Specifying (Non)Linear Solvers</a></li><li><a class="toctext" href="../features/callback_functions.html">Event Handling and Callback Functions</a></li><li><a class="toctext" href="../features/callback_library.html">Callback Library</a></li><li><a class="toctext" href="../features/monte_carlo.html">Parallel Monte Carlo Simulations</a></li><li><a class="toctext" href="../features/io.html">I/O: Saving and Loading Solution Data</a></li><li><a class="toctext" href="../features/low_dep.html">Low Dependency Usage</a></li><li><a class="toctext" href="../features/mesh.html">Meshes</a></li><li><a class="toctext" href="../features/progress_bar.html">Juno Progress Bar Integration</a></li></ul></li><li><span class="toctext">Analysis Tools</span><ul><li><a class="toctext" href="parameterized_functions.html">ParameterizedFunctions</a></li><li class="current"><a class="toctext" href="parameter_estimation.html">Parameter Estimation</a><ul class="internal"><li><a class="toctext" href="#build_loss_objective-1">build_loss_objective</a></li><li><a class="toctext" href="#build_lsoptim_objective-1">build_lsoptim_objective</a></li><li><a class="toctext" href="#lm_fit-1">lm_fit</a></li><li><a class="toctext" href="#Local-Optimization-Examples-1">Local Optimization Examples</a></li><li><a class="toctext" href="#More-Algorithms-(Global-Optimization)-via-MathProgBase-Solvers-1">More Algorithms (Global Optimization) via MathProgBase Solvers</a></li></ul></li><li><a class="toctext" href="bifurcation.html">Bifurcation Analysis</a></li><li><a class="toctext" href="sensitivity.html">Sensitivity Analysis</a></li><li><a class="toctext" href="uncertainty_quantification.html">Uncertainty Quantification</a></li><li><a class="toctext" href="dev_and_test.html">Algorithm Development and Testing</a></li></ul></li><li><span class="toctext">Domain Modeling Tools</span><ul><li><a class="toctext" href="../models/multiscale.html">Multi-Scale Models</a></li><li><a class="toctext" href="../models/financial.html">Financial Models</a></li><li><a class="toctext" href="../models/biological.html">Biological Models</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Analysis Tools</li><li><a href="parameter_estimation.html">Parameter Estimation</a></li></ul><a class="edit-page" href="https://github.com/JuliaDiffEq/DiffEqDocs.jl/tree/8aa11bf6e655ed0abdbbe559d0051b853367945f/docs/src/analysis/parameter_estimation.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Parameter Estimation</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Parameter-Estimation-1" href="#Parameter-Estimation-1">Parameter Estimation</a></h1><p>Parameter estimation for ODE models is provided by the DiffEq suite. The current functionality includes <code>build_loss_objective</code> and <code>lm_fit</code>. Note these require that the problem is defined using a <a href="https://github.com/JuliaDiffEq/ParameterizedFunctions.jl">ParameterizedFunction</a>.</p><h2><a class="nav-anchor" id="build_loss_objective-1" href="#build_loss_objective-1">build_loss_objective</a></h2><p><code>build_loss_objective</code> builds an objective function to be used with Optim.jl and MathProgBase-associated solvers like NLopt.</p><pre><code class="language-julia">function build_loss_objective(prob::DEProblem,alg,loss_func;
                              mpg_autodiff = false,
                              verbose_opt = false,
                              verbose_steps = 100,
                              prob_generator = problem_new_parameters,
                              kwargs...)</code></pre><p>The first argument is the DEProblem to solve, and next is the <code>alg</code> to use. One can also choose <code>verbose_opt</code> and <code>verbose_steps</code>, which, in the optimization routines, will print the steps and the values at the steps every <code>verbose_steps</code> steps. <code>mpg_autodiff</code> uses autodifferentiation to define the derivative for the MathProgBase solver. The extra keyword arguments are passed to the differential equation solver.</p><h3><a class="nav-anchor" id="The-Loss-Function-1" href="#The-Loss-Function-1">The Loss Function</a></h3><pre><code class="language-julia">loss_func(sol)</code></pre><p>is a function which reduces the problem&#39;s solution. While this is very flexible, a two convenience routines is included for fitting to data:</p><pre><code class="language-julia">L2DistLoss(t,data)
CostVData(t,data;loss_func = L2DistLoss)</code></pre><p>where <code>t</code> is the set of timepoints which the data is found at, and <code>data</code> which are the values that are known. <code>L2DistLoss</code> is an optimized version of the L2-distance. In <code>CostVData</code>, one can choose any loss function from LossFunctions.jl or use the default of an L2 loss.</p><h3><a class="nav-anchor" id="The-Problem-Generator-1" href="#The-Problem-Generator-1">The Problem Generator</a></h3><p>The argument <code>prob_generator</code> allows one to specify a the function for generating new problems from a given parameter set. By default, this just builds a new version of <code>f</code> that inserts all of the parameters. For example, for ODEs this is given by the dispatch on <code>DiffEqBase.problem_new_parameters</code> that does the following:</p><pre><code class="language-julia">function problem_new_parameters(prob::ODEProblem,p)
  f = (t,u,du) -&gt; prob.f(t,u,p,du)
  uEltype = eltype(p)
  u0 = [uEltype(prob.u0[i]) for i in 1:length(prob.u0)]
  tspan = (uEltype(prob.tspan[1]),uEltype(prob.tspan[2]))
  ODEProblem(f,u0,tspan)
end</code></pre><p><code>f = (t,u,du) -&gt; prob.f(t,u,p,du)</code> creates a new version of <code>f</code> that encloses the new parameters. The element types for <code>u0</code> and <code>tspan</code> are set to match the parameters. This is required to make autodifferentiation work. Then the new problem with these new values is returned.</p><p>One can use this to change the meaning of the parameters using this function. For example, if one instead wanted to optimize the initial conditions for a function without parameters, you could change this to:</p><pre><code class="language-julia">my_problem_new_parameters = function (prob::ODEProblem,p)
  uEltype = eltype(p)
  tspan = (uEltype(prob.tspan[1]),uEltype(prob.tspan[2]))
  ODEProblem(prob.f,p,tspan)
end</code></pre><p>which simply matches the type for time to <code>p</code> (once again, for autodifferentiation) and uses <code>p</code> as the initial condition in the initial value problem.</p><h2><a class="nav-anchor" id="build_lsoptim_objective-1" href="#build_lsoptim_objective-1">build_lsoptim_objective</a></h2><p><code>build_lsoptim_objective</code> builds an objective function to be used with LeastSquaresOptim.jl.</p><pre><code class="language-julia">build_lsoptim_objective(prob,tspan,t,data;prob_generator = problem_new_parameters,kwargs...)</code></pre><p>The arguments are the same as <code>build_loss_objective</code>.</p><h2><a class="nav-anchor" id="lm_fit-1" href="#lm_fit-1">lm_fit</a></h2><p><code>lm_fit</code> is a function for fitting the parameters of an ODE using the Levenberg-Marquardt algorithm. This algorithm is really bad and thus not recommended since, for example, the Optim.jl algorithms on an L2 loss are more performant and robust. However, this is provided for completeness as most other differential equation libraries use an LM-based algorithm, so this allows one to test the increased effectiveness of not using LM.</p><pre><code class="language-julia">lm_fit(prob::DEProblem,tspan,t,data,p0;prob_generator = problem_new_parameters,kwargs...)</code></pre><p>The arguments are similar to before, but with <code>p0</code> being the initial conditions for the parameters and the <code>kwargs</code> as the args passed to the LsqFit <code>curve_fit</code> function (which is used for the LM solver). This returns the fitted parameters.</p><h2><a class="nav-anchor" id="Local-Optimization-Examples-1" href="#Local-Optimization-Examples-1">Local Optimization Examples</a></h2><p>We choose to optimize the parameters on the Lotka-Volterra equation. We do so by defining the function as a <a href="https://github.com/JuliaDiffEq/ParameterizedFunctions.jl">ParmaeterizedFunction</a>:</p><pre><code class="language-julia">f = @ode_def_nohes LotkaVolterraTest begin
  dx = a*x - b*x*y
  dy = -c*y + d*x*y
end a=&gt;1.5 b=1.0 c=3.0 d=1.0

u0 = [1.0;1.0]
tspan = (0.0,10.0)
prob = ODEProblem(f,u0,tspan)</code></pre><p>Notice that since we only used <code>=&gt;</code> for <code>a</code>, it&#39;s the only free parameter. We create data using the numerical result with <code>a=1.5</code>:</p><pre><code class="language-julia">sol = solve(prob,Tsit5())
t = collect(linspace(0,10,200))
using RecursiveArrayTools # for VectorOfArray
randomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])
data = convert(Array,randomized)</code></pre><p>Here we used <code>VectorOfArray</code> from <a href="https://github.com/ChrisRackauckas/RecursiveArrayTools.jl">RecursiveArrayTools.jl</a> to turn the result of an ODE into a matrix.</p><p>If we plot the solution with the parameter at <code>a=1.42</code>, we get the following:</p><p><img src="../assets/paramest_notfit.png" alt="Parameter Estimation Not Fit"/></p><p>Notice that after one period this solution begins to drift very far off: this problem is sensitive to the choice of <code>a</code>.</p><p>To build the objective function for Optim.jl, we simply call the <code>build_loss_objective</code> funtion:</p><pre><code class="language-julia">cost_function = build_loss_objective(prob,Tsit5(),L2DistLoss(t,data),maxiters=10000)</code></pre><p>Note that we set <code>maxiters</code> so that way the differential equation solvers would error more quickly when in bad regions of the parameter space, speeding up the process. Now this cost function can be used with Optim.jl in order to get the parameters. For example, we can use Brent&#39;s algorithm to search for the best solution on the interval <code>[0,10]</code> by:</p><pre><code class="language-julia">using Optim
result = optimize(cost_function, 0.0, 10.0)</code></pre><p>This returns <code>result.minimizer[1]==1.5</code> as the best parameter to match the data. When we plot the fitted equation on the data, we receive the following:</p><p><img src="../assets/paramest_fit.png" alt="Parameter Estimation Fit"/></p><p>Thus we see that after fitting, the lines match up with the generated data and receive the right parameter value.</p><p>We can also use the multivariate optimization functions. For example, we can use the <code>BFGS</code> algorithm to optimize the parameter starting at <code>a=1.42</code> using:</p><pre><code class="language-julia">result = optimize(cost_function, [1.42], BFGS())</code></pre><p>Note that some of the algorithms may be sensitive to the initial condition. For more details on using Optim.jl, see the <a href="http://www.juliaopt.org/Optim.jl/latest/">documentation for Optim.jl</a>.</p><p>Lastly, we can use the same tools to estimate multiple parameters simultaneously. Let&#39;s use the Lotka-Volterra equation with all parameters free:</p><pre><code class="language-julia">f2 = @ode_def_nohes LotkaVolterraAll begin
  dx = a*x - b*x*y
  dy = -c*y + d*x*y
end a=&gt;1.5 b=&gt;1.0 c=&gt;3.0 d=&gt;1.0

u0 = [1.0;1.0]
tspan = (0.0,10.0)
prob = ODEProblem(f2,u0,tspan)</code></pre><p>To solve it using LeastSquaresOptim.jl, we use the <code>build_lsoptim_objective</code> function:</p><pre><code class="language-julia">cost_function = build_lsoptim_objective(prob,Tsit5(),L2DistLoss(t,data))</code></pre><p>The result is a cost function which can be used with LeastSquaresOptim. For more details, consult the <a href="https://github.com/matthieugomez/LeastSquaresOptim.jl">documentation for LeastSquaresOptim.jl</a>:</p><pre><code class="language-julia">x = [1.3,0.8,2.8,1.2]
res = optimize!(LeastSquaresProblem(x = x, f! = cost_function,
                output_length = length(t)*length(prob.u0)),
                LeastSquaresOptim.Dogleg(),LeastSquaresOptim.LSMR(),
                ftol=1e-14,xtol=1e-15,iterations=100,grtol=1e-14)</code></pre><p>We can see the results are:</p><pre><code class="language-julia">println(res.minimizer)

Results of Optimization Algorithm
 * Algorithm: Dogleg
 * Minimizer: [1.4995074428834114,0.9996531871795851,3.001556360700904,1.0006272074128821]
 * Sum of squares at Minimum: 0.035730
 * Iterations: 63
 * Convergence: true
 * |x - x&#39;| &lt; 1.0e-15: true
 * |f(x) - f(x&#39;)| / |f(x)| &lt; 1.0e-14: false
 * |g(x)| &lt; 1.0e-14: false
 * Function Calls: 64
 * Gradient Calls: 9
 * Multiplication Calls: 135</code></pre><p>and thus this algorithm was able to correctly identify all four parameters.</p><h2><a class="nav-anchor" id="More-Algorithms-(Global-Optimization)-via-MathProgBase-Solvers-1" href="#More-Algorithms-(Global-Optimization)-via-MathProgBase-Solvers-1">More Algorithms (Global Optimization) via MathProgBase Solvers</a></h2><p>The <code>build_loss_objective</code> function builds an objective function which is able to be used with MathProgBase-associated solvers. This includes packages like IPOPT, NLopt, MOSEK, etc. Building off of the previous example, we can build a cost function for the single parameter optimization problem like:</p><pre><code class="language-julia">f = @ode_def_nohes LotkaVolterraTest begin
  dx = a*x - b*x*y
  dy = -c*y + d*x*y
end a=&gt;1.5 b=1.0 c=3.0 d=1.0

u0 = [1.0;1.0]
tspan = (0.0,10.0)
prob = ODEProblem(f,u0,tspan)
sol = solve(prob,Tsit5())

t = collect(linspace(0,10,200))
randomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])
data = convert(Array,randomized)

obj = build_loss_objective(prob,Tsit5(),L2DistLoss(t,data),maxiters=10000)</code></pre><p>We can now use this <code>obj</code> as the objective function with MathProgBase solvers. For our example, we will use NLopt. To use the local derivative-free Constrained Optimization BY Linear Approximations algorithm, we can simply do:</p><pre><code class="language-julia">using NLopt
opt = Opt(:LN_COBYLA, 1)
min_objective!(opt, obj)
(minf,minx,ret) = NLopt.optimize(opt,[1.3])</code></pre><p>This finds a minimum at <code>[1.49997]</code>. For a modified evolutionary algorithm, we can use:</p><pre><code class="language-julia">opt = Opt(:GN_ESCH, 1)
min_objective!(opt, obj.cost_function2)
lower_bounds!(opt,[0.0])
upper_bounds!(opt,[5.0])
xtol_rel!(opt,1e-3)
maxeval!(opt, 100000)
(minf,minx,ret) = NLopt.optimize(opt,[1.3])</code></pre><p>We can even use things like the Improved Stochastic Ranking Evolution Strategy (and add constraints if needed). This is done via:</p><pre><code class="language-julia">opt = Opt(:GN_ISRES, 1)
min_objective!(opt, obj.cost_function2)
lower_bounds!(opt,[-1.0])
upper_bounds!(opt,[5.0])
xtol_rel!(opt,1e-3)
maxeval!(opt, 100000)
(minf,minx,ret) = NLopt.optimize(opt,[0.2])</code></pre><p>which is very robust to the initial condition. The fastest result comes from the following:</p><pre><code class="language-julia">using NLopt
opt = Opt(:LN_BOBYQA, 1)
min_objective!(opt, obj)
(minf,minx,ret) = NLopt.optimize(opt,[1.3])</code></pre><p>For more information, see the NLopt documentation for more details. And give IPOPT or MOSEK a try!</p><footer><hr/><a class="previous" href="parameterized_functions.html"><span class="direction">Previous</span><span class="title">ParameterizedFunctions</span></a><a class="next" href="bifurcation.html"><span class="direction">Next</span><span class="title">Bifurcation Analysis</span></a></footer></article></body></html>
