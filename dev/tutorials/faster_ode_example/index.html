<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Code Optimization for Differential Equations · DifferentialEquations.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://diffeq.sciml.ai/stable/tutorials/faster_ode_example/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DifferentialEquations.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DifferentialEquations.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">DifferentialEquations.jl: Scientific Machine Learning (SciML) Enabled Simulation and Estimation</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../ode_example/">Ordinary Differential Equations</a></li><li class="is-active"><a class="tocitem" href>Code Optimization for Differential Equations</a><ul class="internal"><li><a class="tocitem" href="#Code-Optimization-in-Julia"><span>Code Optimization in Julia</span></a></li><li><a class="tocitem" href="#Example-Accelerating-a-Non-Stiff-Equation:-The-Lorenz-Equation"><span>Example Accelerating a Non-Stiff Equation: The Lorenz Equation</span></a></li><li><a class="tocitem" href="#Example-Accelerating-a-Stiff-Equation:-the-Robertson-Equation"><span>Example Accelerating a Stiff Equation: the Robertson Equation</span></a></li><li><a class="tocitem" href="#Example-Accelerating-Linear-Algebra-PDE-Semi-Discretization"><span>Example Accelerating Linear Algebra PDE Semi-Discretization</span></a></li></ul></li><li><a class="tocitem" href="../advanced_ode_example/">Solving Large Stiff Equations</a></li><li><a class="tocitem" href="../sde_example/">Stochastic Differential Equations</a></li><li><a class="tocitem" href="../rode_example/">Random Ordinary Differential Equations</a></li><li><a class="tocitem" href="../dde_example/">Delay Differential Equations</a></li><li><a class="tocitem" href="../dae_example/">Differential Algebraic Equations</a></li><li><a class="tocitem" href="../discrete_stochastic_example/">Continuous-Time Jump Processes and Gillespie Methods</a></li><li><a class="tocitem" href="../jump_diffusion/">Jump Diffusion Equations</a></li><li><a class="tocitem" href="../bvp_example/">Boundary Value Problems</a></li><li><a class="tocitem" href="../additional/">Additional Tutorials</a></li></ul></li><li><span class="tocitem">Basics</span><ul><li><a class="tocitem" href="../../basics/overview/">Overview of DifferentialEquations.jl</a></li><li><a class="tocitem" href="../../basics/common_solver_opts/">Common Solver Options (Solve Keyword Arguments)</a></li><li><a class="tocitem" href="../../basics/solution/">Solution Handling</a></li><li><a class="tocitem" href="../../basics/plot/">Plot Functions</a></li><li><a class="tocitem" href="../../basics/integrator/">Integrator Interface</a></li><li><a class="tocitem" href="../../basics/problem/">Problem Interface</a></li><li><a class="tocitem" href="../../basics/faq/">Frequently Asked Questions</a></li><li><a class="tocitem" href="../../basics/compatibility_chart/">Solver Compatibility Chart</a></li></ul></li><li><span class="tocitem">Problem Types</span><ul><li><a class="tocitem" href="../../types/discrete_types/">Discrete Problems</a></li><li><a class="tocitem" href="../../types/ode_types/">ODE Problems</a></li><li><a class="tocitem" href="../../types/nonautonomous_linear_ode/">Non-autonomous Linear ODE / Lie Group Problems</a></li><li><a class="tocitem" href="../../types/dynamical_types/">Dynamical, Hamiltonian and 2nd Order ODE Problems</a></li><li><a class="tocitem" href="../../types/split_ode_types/">Split ODE Problems</a></li><li><a class="tocitem" href="../../types/steady_state_types/">Steady State Problems</a></li><li><a class="tocitem" href="../../types/bvp_types/">BVP Problems</a></li><li><a class="tocitem" href="../../types/sde_types/">SDE Problems</a></li><li><a class="tocitem" href="../../types/sdae_types/">SDAE Problems</a></li><li><a class="tocitem" href="../../types/rode_types/">RODE Problems</a></li><li><a class="tocitem" href="../../types/dde_types/">DDE Problems</a></li><li><a class="tocitem" href="../../types/sdde_types/">SDDE Problems</a></li><li><a class="tocitem" href="../../types/dae_types/">DAE Problems</a></li><li><a class="tocitem" href="../../types/jump_types/">Jump Problems</a></li></ul></li><li><span class="tocitem">Solver Algorithms</span><ul><li><a class="tocitem" href="../../solvers/discrete_solve/">Discrete Solvers</a></li><li><a class="tocitem" href="../../solvers/ode_solve/">ODE Solvers</a></li><li><a class="tocitem" href="../../solvers/nonautonomous_linear_ode/">Non-autonomous Linear ODE / Lie Group ODE Solvers</a></li><li><a class="tocitem" href="../../solvers/dynamical_solve/">Dynamical, Hamiltonian, and 2nd Order ODE Solvers</a></li><li><a class="tocitem" href="../../solvers/split_ode_solve/">Split ODE Solvers</a></li><li><a class="tocitem" href="../../solvers/steady_state_solve/">Steady State Solvers</a></li><li><a class="tocitem" href="../../solvers/bvp_solve/">BVP Solvers</a></li><li><a class="tocitem" href="../../solvers/jump_solve/">Jump Problem and Jump Diffusion Solvers</a></li><li><a class="tocitem" href="../../solvers/sde_solve/">SDE Solvers</a></li><li><a class="tocitem" href="../../solvers/sdae_solve/">SDAE Solvers</a></li><li><a class="tocitem" href="../../solvers/rode_solve/">RODE Solvers</a></li><li><a class="tocitem" href="../../solvers/dde_solve/">DDE Solvers</a></li><li><a class="tocitem" href="../../solvers/sdde_solve/">SDDE Solvers</a></li><li><a class="tocitem" href="../../solvers/dae_solve/">DAE Solvers</a></li><li><a class="tocitem" href="../../solvers/benchmarks/">Solver Benchmarks</a></li></ul></li><li><span class="tocitem">Additional Features</span><ul><li><a class="tocitem" href="../../features/performance_overloads/">Jacobians, Gradients, etc.</a></li><li><a class="tocitem" href="../../features/diffeq_arrays/">DiffEq-Specific Array Types</a></li><li><a class="tocitem" href="../../features/diffeq_operator/">DiffEqOperators</a></li><li><a class="tocitem" href="../../features/noise_process/">Noise Processes</a></li><li><a class="tocitem" href="../../features/linear_nonlinear/">Specifying (Non)Linear Solvers and Preconditioners</a></li><li><a class="tocitem" href="../../features/callback_functions/">Event Handling and Callback Functions</a></li><li><a class="tocitem" href="../../features/callback_library/">Callback Library</a></li><li><a class="tocitem" href="../../features/ensemble/">Parallel Ensemble Simulations</a></li><li><a class="tocitem" href="../../features/io/">I/O: Saving and Loading Solution Data</a></li><li><a class="tocitem" href="../../features/low_dep/">Reduced Compile Time, Optimizing Runtime, and Low Dependency Usage</a></li><li><a class="tocitem" href="../../features/progress_bar/">Progress Bar Integration</a></li></ul></li><li><span class="tocitem">Analysis Tools</span><ul><li><a class="tocitem" href="../../analysis/parameterized_functions/">ParameterizedFunctions</a></li><li><a class="tocitem" href="../../analysis/parameter_estimation/">Parameter Estimation and Bayesian Analysis</a></li><li><a class="tocitem" href="../../analysis/bifurcation/">Bifurcation Analysis</a></li><li><a class="tocitem" href="../../analysis/sensitivity/">Local Sensitivity Analysis (Automatic Differentiation)</a></li><li><a class="tocitem" href="../../analysis/global_sensitivity/">Global Sensitivity Analysis</a></li><li><a class="tocitem" href="../../analysis/uncertainty_quantification/">Uncertainty Quantification</a></li><li><a class="tocitem" href="../../analysis/neural_networks/">Neural Networks</a></li><li><a class="tocitem" href="../../analysis/dev_and_test/">Algorithm Development and Testing</a></li></ul></li><li><span class="tocitem">Domain Modeling Tools</span><ul><li><a class="tocitem" href="../../models/multiscale/">Multi-Scale Models</a></li><li><a class="tocitem" href="../../models/physical/">Physical Models</a></li><li><a class="tocitem" href="../../models/financial/">Financial Models</a></li><li><a class="tocitem" href="../../models/chemical_reactions/">Chemical Reactions</a></li><li><a class="tocitem" href="../../models/external_modeling/">External Modeling Packages</a></li></ul></li><li><span class="tocitem">Extra Details</span><ul><li><a class="tocitem" href="../../extras/timestepping/">Timestepping Method Descriptions</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Code Optimization for Differential Equations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Code Optimization for Differential Equations</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DiffEqDocs.jl/blob/master/docs/src/tutorials/faster_ode_example.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="speed"><a class="docs-heading-anchor" href="#speed">Code Optimization for Differential Equations</a><a id="speed-1"></a><a class="docs-heading-anchor-permalink" href="#speed" title="Permalink"></a></h1><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>See <a href="../../basics/faq/#faq_performance">this FAQ</a> for information on common pitfalls and how to improve performance.</p></div></div><h2 id="Code-Optimization-in-Julia"><a class="docs-heading-anchor" href="#Code-Optimization-in-Julia">Code Optimization in Julia</a><a id="Code-Optimization-in-Julia-1"></a><a class="docs-heading-anchor-permalink" href="#Code-Optimization-in-Julia" title="Permalink"></a></h2><p>Before starting this tutorial, we recommend the reader to check out one of the many tutorials for optimization Julia code. The following is an incomplete list:</p><ul><li><a href="https://docs.julialang.org/en/v1/manual/performance-tips/">The Julia Performance Tips</a></li><li><a href="https://mitmath.github.io/18337/lecture2/optimizing">MIT 18.337 Course Notes on Optimizing Serial Code</a></li><li><a href="https://biojulia.net/post/hardware/">What scientists must know about hardware to write fast code</a></li></ul><p>User-side optimizations are important because, for sufficiently difficult problems, most of the time will be spent inside of your <code>f</code> function, the function you are trying to solve. &quot;Efficient&quot; integrators are those that reduce the required number of <code>f</code> calls to hit the error tolerance. The main ideas for optimizing your DiffEq code, or any Julia function, are the following:</p><ul><li>Make it non-allocating</li><li>Use StaticArrays for small arrays</li><li>Use broadcast fusion</li><li>Make it type-stable</li><li>Reduce redundant calculations</li><li>Make use of BLAS calls</li><li>Optimize algorithm choice</li></ul><p>We&#39;ll discuss these strategies in the context of differential equations. Let&#39;s start with small systems.</p><h2 id="Example-Accelerating-a-Non-Stiff-Equation:-The-Lorenz-Equation"><a class="docs-heading-anchor" href="#Example-Accelerating-a-Non-Stiff-Equation:-The-Lorenz-Equation">Example Accelerating a Non-Stiff Equation: The Lorenz Equation</a><a id="Example-Accelerating-a-Non-Stiff-Equation:-The-Lorenz-Equation-1"></a><a class="docs-heading-anchor-permalink" href="#Example-Accelerating-a-Non-Stiff-Equation:-The-Lorenz-Equation" title="Permalink"></a></h2><p>Let&#39;s take the classic Lorenz system. Let&#39;s start by naively writing the system in its out-of-place form:</p><pre><code class="language-julia hljs">function lorenz(u,p,t)
 dx = 10.0*(u[2]-u[1])
 dy = u[1]*(28.0-u[3]) - u[2]
 dz = u[1]*u[2] - (8/3)*u[3]
 [dx,dy,dz]
end</code></pre><p>Here, <code>lorenz</code> returns an object, <code>[dx,dy,dz]</code>, which is created within the body of <code>lorenz</code>.</p><p>This is a common code pattern from high-level languages like MATLAB, SciPy, or R&#39;s deSolve. However, the issue with this form is that it allocates a vector, <code>[dx,dy,dz]</code>, at each step. Let&#39;s benchmark the solution process with this choice of function:</p><pre><code class="language-julia hljs">using DifferentialEquations, BenchmarkTools
u0 = [1.0;0.0;0.0]
tspan = (0.0,100.0)
prob = ODEProblem(lorenz,u0,tspan)
@benchmark solve(prob,Tsit5())</code></pre><pre><code class="language-julia hljs">BenchmarkTools.Trial: 1350 samples with 1 evaluation.
 Range (min … max):  2.296 ms … 13.764 ms  ┊ GC (min … max):  0.00% … 67.48%
 Time  (median):     2.561 ms              ┊ GC (median):     0.00%
 Time  (mean ± σ):   3.699 ms ±  2.223 ms  ┊ GC (mean ± σ):  14.83% ± 17.79%

  █▆▄       ▁ ▃▄▃▄▂
  ████▆▆█▇▇▇█▇█████▆▄▄▄▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▆▇▆▇▇▆▇▇▆█▇▇▆ █
  2.3 ms       Histogram: log(frequency) by time     11.3 ms &lt;

 Memory estimate: 7.82 MiB, allocs estimate: 101102.</code></pre><p>The <code>BenchmarkTools.jl</code> package&#39;s <code>@benchmark</code> runs the code multiple times to get an accurate measurement. The minimum time is the time it takes when your OS and other background processes aren&#39;t getting in the way. Notice that in this case it takes about 5ms to solve and allocates around 11.11 MiB. However, if we were to use this inside of a real user code we&#39;d see a lot of time spent doing garbage collection (GC) to clean up all of the arrays we made. Even if we turn off saving we have these allocations.</p><pre><code class="language-julia hljs">@benchmark solve(prob,Tsit5(),save_everystep=false)

BenchmarkTools.Trial: 1490 samples with 1 evaluation.
 Range (min … max):  2.010 ms … 14.612 ms  ┊ GC (min … max):  0.00% … 65.56%
 Time  (median):     2.313 ms              ┊ GC (median):     0.00%
 Time  (mean ± σ):   3.350 ms ±  2.095 ms  ┊ GC (mean ± σ):  14.55% ± 17.48%

  █▇▅▁       ▃▅▅▄▃
  █████▇▇▇▆▇███████▅▁▄▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▅▇▇▆▆█▇▇▆▆▆▆ █
  2.01 ms      Histogram: log(frequency) by time       11 ms &lt;

 Memory estimate: 6.83 MiB, allocs estimate: 89529.</code></pre><p>The problem of course is that arrays are created every time our derivative function is called. This function is called multiple times per step and is thus the main source of memory usage. To fix this, we can use the in-place form to ***make our code non-allocating***:</p><pre><code class="language-julia hljs">function lorenz!(du,u,p,t)
 du[1] = 10.0*(u[2]-u[1])
 du[2] = u[1]*(28.0-u[3]) - u[2]
 du[3] = u[1]*u[2] - (8/3)*u[3]
 nothing
end</code></pre><p>Here, instead of creating an array each time, we utilized the cache array <code>du</code>. When the in-place form is used, DifferentialEquations.jl takes a different internal route that minimizes the internal allocations as well.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Notice that nothing is returned. When in in-place form, the ODE solver ignores the return. Instead, make sure that the original <code>du</code> array is mutated instead of constructing a new array</p></div></div><p>When we benchmark this function, we will see quite a difference.</p><pre><code class="language-julia hljs">u0 = [1.0;0.0;0.0]
tspan = (0.0,100.0)
prob = ODEProblem(lorenz!,u0,tspan)
@benchmark solve(prob,Tsit5())

BenchmarkTools.Trial: 8180 samples with 1 evaluation.
 Range (min … max):  415.800 μs …  12.112 ms  ┊ GC (min … max):  0.00% … 93.21%
 Time  (median):     463.700 μs               ┊ GC (median):     0.00%
 Time  (mean ± σ):   605.847 μs ± 695.892 μs  ┊ GC (mean ± σ):  11.02% ±  9.07%

  ▄█▇▅▃▂▂▂▂▁▁▄▅▅▃▂▂▂▁▂▁▁                                        ▂
  ███████████████████████▇▇▇▇▇▆▆▆▅▅▄▄▅▃▅▄▅▄▅▄▁▅▁▃▄▁▃▁▁▁▁▃▄▁▁▄▁▃ █
  416 μs        Histogram: log(frequency) by time       1.68 ms &lt;

 Memory estimate: 1016.36 KiB, allocs estimate: 11641.</code></pre><pre><code class="language-julia hljs">@benchmark solve(prob,Tsit5(),save_everystep=false)

BenchmarkTools.Trial: 10000 samples with 1 evaluation.
 Range (min … max):  197.900 μs … 315.800 μs  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     206.700 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   207.688 μs ±   6.241 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%

          ▃▅▅▇█▅▃       ▁▁▂▁▃▂▁
  ▁▁▁▂▃▃▅▇█████████▇▇▇▆█████████▆▆▅▅▃▂▃▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▃
  198 μs           Histogram: frequency by time          227 μs &lt;

 Memory estimate: 4.94 KiB, allocs estimate: 41.</code></pre><p>There is a 16x time difference just from that change! Notice there are still some allocations and this is due to the construction of the integration cache. But this doesn&#39;t scale with the problem size:</p><pre><code class="language-julia hljs">tspan = (0.0,500.0) # 5x longer than before
prob = ODEProblem(lorenz!,u0,tspan)
@benchmark solve(prob,Tsit5(),save_everystep=false)

BenchmarkTools.Trial: 4755 samples with 1 evaluation.
 Range (min … max):  1.014 ms …  1.485 ms  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     1.042 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   1.048 ms ± 31.281 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%

    ▁▆▆▅▇█▇▆▆▂▁ ▁            ▁
  ▂▄█████████████▇▇▇▇▇▇█▇▇█▇███▇█▇▇▅▆▄▄▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁ ▄
  1.01 ms        Histogram: frequency by time        1.12 ms &lt;

 Memory estimate: 4.94 KiB, allocs estimate: 41.</code></pre><p>Since that&#39;s all setup allocations the user-side optimization is complete.</p><h3 id="Further-Optimizations-of-Small-Non-Stiff-ODEs-with-StaticArrays"><a class="docs-heading-anchor" href="#Further-Optimizations-of-Small-Non-Stiff-ODEs-with-StaticArrays">Further Optimizations of Small Non-Stiff ODEs with StaticArrays</a><a id="Further-Optimizations-of-Small-Non-Stiff-ODEs-with-StaticArrays-1"></a><a class="docs-heading-anchor-permalink" href="#Further-Optimizations-of-Small-Non-Stiff-ODEs-with-StaticArrays" title="Permalink"></a></h3><p>Allocations are only expensive if they are &quot;heap allocations&quot;. For a more in-depth definition of heap allocations, <a href="http://net-informations.com/faq/net/stack-heap.htm">there are a lot of sources online</a>. But a good working definition is that heap allocations are variable-sized slabs of memory which have to be pointed to, and this pointer indirection costs time. Additionally, the heap has to be managed and the garbage controllers has to actively keep track of what&#39;s on the heap.</p><p>However, there&#39;s an alternative to heap allocations, known as stack allocations. The stack is statically-sized (known at compile time) and thus its accesses are quick. Additionally, the exact block of memory is known in advance by the compiler, and thus re-using the memory is cheap. This means that allocating on the stack has essentially no cost!</p><p>Arrays have to be heap allocated because their size (and thus the amount of memory they take up) is determined at runtime. But there are structures in Julia which are stack-allocated. <code>struct</code>s for example are stack-allocated &quot;value-type&quot;s. <code>Tuple</code>s are a stack-allocated collection. The most useful data structure for DiffEq though is the <code>StaticArray</code> from the package <a href="https://github.com/JuliaArrays/StaticArrays.jl">StaticArrays.jl</a>. These arrays have their length determined at compile-time. They are created using macros attached to normal array expressions, for example:</p><pre><code class="language-julia hljs">using StaticArrays
A = SA[2.0,3.0,5.0]
typeof(A) # SVector{3, Float64} (alias for SArray{Tuple{3}, Float64, 1, 3})</code></pre><p>Notice that the <code>3</code> after <code>SVector</code> gives the size of the <code>SVector</code>. It cannot be changed. Additionally, <code>SVector</code>s are immutable, so we have to create a new <code>SVector</code> to change values. But remember, we don&#39;t have to worry about allocations because this data structure is stack-allocated. <code>SArray</code>s have a lot of extra optimizations as well: they have fast matrix multiplication, fast QR factorizations, etc. which directly make use of the information about the size of the array. Thus, when possible they should be used.</p><p>Unfortunately static arrays can only be used for sufficiently small arrays. After a certain size, they are forced to heap allocate after some instructions and their compile time balloons. Thus static arrays shouldn&#39;t be used if your system has more than ~20 variables. Additionally, only the native Julia algorithms can fully utilize static arrays.</p><p>Let&#39;s ***optimize <code>lorenz</code> using static arrays***. Note that in this case, we want to use the out-of-place allocating form, but this time we want to output a static array:</p><pre><code class="language-julia hljs">function lorenz_static(u,p,t)
 dx = 10.0*(u[2]-u[1])
 dy = u[1]*(28.0-u[3]) - u[2]
 dz = u[1]*u[2] - (8/3)*u[3]
 SA[dx,dy,dz]
end</code></pre><p>To make the solver internally use static arrays, we simply give it a static array as the initial condition:</p><pre><code class="language-julia hljs">u0 = SA[1.0,0.0,0.0]
tspan = (0.0,100.0)
prob = ODEProblem(lorenz_static,u0,tspan)
@benchmark solve(prob,Tsit5())

BenchmarkTools.Trial: 10000 samples with 1 evaluation.
 Range (min … max):  196.600 μs …   6.310 ms  ┊ GC (min … max): 0.00% … 95.70%
 Time  (median):     220.900 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   265.006 μs ± 302.623 μs  ┊ GC (mean ± σ):  6.91% ±  5.82%

    ▅█▄▄▄
  ▁▄██████▅▄▃▂▂▁▁▂▁▁▁▁▁▁▁▂▃▄▅▅▆▆▆▅▅▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▂
  197 μs           Histogram: frequency by time          374 μs &lt;

 Memory estimate: 394.50 KiB, allocs estimate: 1319.</code></pre><pre><code class="language-julia hljs">@benchmark solve(prob,Tsit5(),save_everystep=false)

BenchmarkTools.Trial: 10000 samples with 1 evaluation.
 Range (min … max):  144.100 μs … 242.600 μs  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     151.000 μs               ┊ GC (median):    0.00%
 Time  (mean ± σ):   151.875 μs ±   7.502 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%

      █▇▇▂   ▁▅▄▂▂
  ▂▂▃█████▇▇▇██████▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂ ▃
  144 μs           Histogram: frequency by time          185 μs &lt;

 Memory estimate: 3.67 KiB, allocs estimate: 22.</code></pre><p>And that&#39;s pretty much all there is to it. With static arrays you don&#39;t have to worry about allocating, so use operations like <code>*</code> and don&#39;t worry about fusing operations (discussed in the next section). Do &quot;the vectorized code&quot; of R/MATLAB/Python and your code in this case will be fast, or directly use the numbers/values.</p><h2 id="Example-Accelerating-a-Stiff-Equation:-the-Robertson-Equation"><a class="docs-heading-anchor" href="#Example-Accelerating-a-Stiff-Equation:-the-Robertson-Equation">Example Accelerating a Stiff Equation: the Robertson Equation</a><a id="Example-Accelerating-a-Stiff-Equation:-the-Robertson-Equation-1"></a><a class="docs-heading-anchor-permalink" href="#Example-Accelerating-a-Stiff-Equation:-the-Robertson-Equation" title="Permalink"></a></h2><p>For these next examples, let&#39;s solve the Robertson equations (also known as ROBER):</p><p class="math-container">\[\begin{aligned}
\frac{dy_1}{dt} &amp;= -0.04y₁ + 10^4 y_2 y_3 \\
\frac{dy_2}{dt} &amp;= 0.04 y_1 - 10^4 y_2 y_3 - 3*10^7 y_{2}^2 \\
\frac{dy_3}{dt} &amp;= 3*10^7 y_{2}^2 \\
\end{aligned}\]</p><p>Given that these equations are stiff, non-stiff ODE solvers like <code>Tsit5</code> or <code>Vern9</code> will fail to solve these equations. The automatic algorithm will detect this and automatically switch to something more robust to handle these issues. For example:</p><pre><code class="language-julia hljs">using DifferentialEquations
function rober!(du,u,p,t)
  y₁,y₂,y₃ = u
  k₁,k₂,k₃ = p
  du[1] = -k₁*y₁+k₃*y₂*y₃
  du[2] =  k₁*y₁-k₂*y₂^2-k₃*y₂*y₃
  du[3] =  k₂*y₂^2
  nothing
end
prob = ODEProblem(rober!,[1.0,0.0,0.0],(0.0,1e5),[0.04,3e7,1e4])
sol = solve(prob)
plot(sol,tspan=(1e-2,1e5),xscale=:log10)</code></pre><p><img src="../../assets/intro_dae_plot.png" alt="IntroDAEPlot"/></p><pre><code class="language-julia-repl hljs">julia&gt; using BenchmarkTools
julia&gt; @btime solve(prob)
97.000 μs (1832 allocations: 132.30 KiB)</code></pre><h3 id="Choosing-a-Good-Solver"><a class="docs-heading-anchor" href="#Choosing-a-Good-Solver">Choosing a Good Solver</a><a id="Choosing-a-Good-Solver-1"></a><a class="docs-heading-anchor-permalink" href="#Choosing-a-Good-Solver" title="Permalink"></a></h3><p>Choosing a good solver is required for getting top notch speed. General recommendations can be found on the solver page (for example, the <a href="../../solvers/ode_solve/#ode_solve">ODE Solver Recommendations</a>). The current recommendations can be simplified to a Rosenbrock method (<code>Rosenbrock23</code> or <code>Rodas5</code>) for smaller (&lt;50 ODEs) problems, ESDIRK methods for slightly larger (<code>TRBDF2</code> or <code>KenCarp4</code> for &lt;2000 ODEs), and <code>QNDF</code> for even larger problems. <code>lsoda</code> from <a href="https://github.com/rveltz/LSODA.jl">LSODA.jl</a> is sometimes worth a try for the medium sized category.</p><p>More details on the solver to choose can be found by benchmarking. See the <a href="https://github.com/SciML/SciMLBenchmarks.jl">SciMLBenchmarks</a> to compare many solvers on many problems.</p><p>From this, we try the recommendation of <code>Rosenbrock23()</code> for stiff ODEs at default tolerances:</p><pre><code class="language-julia hljs">@btime solve(prob,Rosenbrock23())
# 61.200 μs (918 allocations: 78.72 KiB)</code></pre><h3 id="Declaring-Jacobian-Functions"><a class="docs-heading-anchor" href="#Declaring-Jacobian-Functions">Declaring Jacobian Functions</a><a id="Declaring-Jacobian-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Declaring-Jacobian-Functions" title="Permalink"></a></h3><p>In order to reduce the Jacobian construction cost, one can describe a Jacobian function by using the <code>jac</code> argument for the <code>ODEFunction</code>. First we have to derive the Jacobian <span>$\frac{df_i}{du_j}$</span> which is <code>J[i,j]</code>. From this we get:</p><pre><code class="language-julia hljs">function rober_jac!(J,u,p,t)
  y₁,y₂,y₃ = u
  k₁,k₂,k₃ = p
  J[1,1] = k₁ * -1
  J[2,1] = k₁
  J[3,1] = 0
  J[1,2] = y₃ * k₃
  J[2,2] = y₂ * k₂ * -2 + y₃ * k₃ * -1
  J[3,2] = y₂ * 2 * k₂
  J[1,3] = k₃ * y₂
  J[2,3] = k₃ * y₂ * -1
  J[3,3] = 0
  nothing
end
f! = ODEFunction(rober!, jac=rober_jac!)
prob_jac = ODEProblem(f!,[1.0,0.0,0.0],(0.0,1e5),(0.04,3e7,1e4))</code></pre><pre><code class="language-julia-repl hljs">julia&gt; @btime solve(prob_jac,Rosenbrock23())
57.400 μs (978 allocations: 82.58 KiB)</code></pre><h3 id="Automatic-Derivation-of-Jacobian-Functions"><a class="docs-heading-anchor" href="#Automatic-Derivation-of-Jacobian-Functions">Automatic Derivation of Jacobian Functions</a><a id="Automatic-Derivation-of-Jacobian-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Derivation-of-Jacobian-Functions" title="Permalink"></a></h3><p>But that was hard! If you want to take the symbolic Jacobian of numerical code, we can make use of <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a> to symbolic-ify the numerical code and do the symbolic calculation and return the Julia code for this.</p><pre><code class="language-julia hljs">using ModelingToolkit
de = modelingtoolkitize(prob)</code></pre><p>We can tell it to compute the Jacobian if we want to see the code:</p><pre><code class="language-julia hljs">julia&gt; ModelingToolkit.generate_jacobian(de)[2] # Second is in-place
:(function (ˍ₋out, ˍ₋arg1, ˍ₋arg2, t)
      #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:303 =#
      #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:304 =#
      let var&quot;x₁(t)&quot; = #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:190 =# @inbounds(ˍ₋arg1[1]), var&quot;x₂(t)&quot; = #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:190 =# @inbounds(ˍ₋arg1[2]), var&quot;x₃(t)&quot; = #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:190 =# @inbounds(ˍ₋arg1[3]), α₁ = #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:190 =# @inbounds(ˍ₋arg2[1]), α₂ = #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:190 =# @inbounds(ˍ₋arg2[2]), α₃ = #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:190 =# @inbounds(ˍ₋arg2[3])
          #= C:\Users\accou\.julia\dev\Symbolics\src\build_function.jl:378 =#
          #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:350 =# @inbounds begin
                  #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:346 =#
                  ˍ₋out[1] = (*)(-1, α₁)
                  ˍ₋out[2] = α₁
                  ˍ₋out[3] = 0
                  ˍ₋out[4] = (*)(α₃, var&quot;x₃(t)&quot;)
                  ˍ₋out[5] = (+)((*)((*)(-2, α₂), var&quot;x₂(t)&quot;), (*)((*)(-1, α₃), var&quot;x₃(t)&quot;))
                  ˍ₋out[6] = (*)((*)(2, α₂), var&quot;x₂(t)&quot;)
                  ˍ₋out[7] = (*)(α₃, var&quot;x₂(t)&quot;)
                  ˍ₋out[8] = (*)((*)(-1, α₃), var&quot;x₂(t)&quot;)
                  ˍ₋out[9] = 0
                  #= C:\Users\accou\.julia\packages\SymbolicUtils\0KTj4\src\code.jl:348 =#
                  nothing
              end
      end
  end)</code></pre><p>Now let&#39;s use that to give the analytical solution Jacobian:</p><pre><code class="language-julia hljs">prob_jac2 = ODEProblem(de,[],(0.0,1e5),jac=true)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; @btime solve(prob_jac2)
122.600 μs (1425 allocations: 99.34 KiB)</code></pre><p>See the <a href="https://mtk.sciml.ai/dev/">ModelingToolkit.jl documentation</a> for more details.</p><h3 id="Accelerating-Small-ODE-Solves-with-Static-Arrays"><a class="docs-heading-anchor" href="#Accelerating-Small-ODE-Solves-with-Static-Arrays">Accelerating Small ODE Solves with Static Arrays</a><a id="Accelerating-Small-ODE-Solves-with-Static-Arrays-1"></a><a class="docs-heading-anchor-permalink" href="#Accelerating-Small-ODE-Solves-with-Static-Arrays" title="Permalink"></a></h3><p>If the ODE is sufficiently small (&lt;20 ODEs or so), using <a href="https://github.com/JuliaArrays/StaticArrays.jl">StaticArrays.jl</a> for the state variables can greatly enhance the performance. This is done by making <code>u0</code> a <code>StaticArray</code> and writing an out-of-place non-mutating dispatch for static arrays, for the ROBER problem, this looks like:</p><pre><code class="language-julia hljs">using DifferentialEquations, StaticArrays
function rober_static(u,p,t)
  y₁,y₂,y₃ = u
  k₁,k₂,k₃ = p
  du1 = -k₁*y₁+k₃*y₂*y₃
  du2 =  k₁*y₁-k₂*y₂^2-k₃*y₂*y₃
  du3 =  k₂*y₂^2
  SA[du1,du2,du3]
end
prob = ODEProblem(rober_static,SA[1.0,0.0,0.0],(0.0,1e5),SA[0.04,3e7,1e4])
sol = solve(prob,Rosenbrock23())</code></pre><p>If we benchmark this we see a really fast solution with really low allocation counts:</p><pre><code class="language-julia hljs">@btime sol = solve(prob,Rosenbrock23())
# 12.100 μs (87 allocations: 18.53 KiB)</code></pre><p>This version is thus very amenable to multithreading and other forms of parallelism.</p><h2 id="Example-Accelerating-Linear-Algebra-PDE-Semi-Discretization"><a class="docs-heading-anchor" href="#Example-Accelerating-Linear-Algebra-PDE-Semi-Discretization">Example Accelerating Linear Algebra PDE Semi-Discretization</a><a id="Example-Accelerating-Linear-Algebra-PDE-Semi-Discretization-1"></a><a class="docs-heading-anchor-permalink" href="#Example-Accelerating-Linear-Algebra-PDE-Semi-Discretization" title="Permalink"></a></h2><p>In this tutorial we will optimize the right-hand side definition of a PDE semi-discretization.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>We highly recommend looking at the <a href="../advanced_ode_example/#stiff">Solving Large Stiff Equations</a> tutorial for details on customizing DifferentialEquations.jl for more efficient large-scale stiff ODE solving. This section will only focus on the user-side code.</p></div></div><p>Let&#39;s optimize the solution of a Reaction-Diffusion PDE&#39;s discretization. In its discretized form, this is the ODE:</p><p class="math-container">\[\begin{align}
du &amp;= D_1 (A_y u + u A_x) + \frac{au^2}{v} + \bar{u} - \alpha u\\
dv &amp;= D_2 (A_y v + v A_x) + a u^2 + \beta v
\end{align}\]</p><p>where <span>$u$</span>, <span>$v$</span>, and <span>$A$</span> are matrices. Here, we will use the simplified version where <span>$A$</span> is the tridiagonal stencil <span>$[1,-2,1]$</span>, i.e. it&#39;s the 2D discretization of the LaPlacian. The native code would be something along the lines of:</p><pre><code class="language-julia hljs">using DifferentialEquations, LinearAlgebra
# Generate the constants
p = (1.0,1.0,1.0,10.0,0.001,100.0) # a,α,ubar,β,D1,D2
N = 100
Ax = Array(Tridiagonal([1.0 for i in 1:N-1],[-2.0 for i in 1:N],[1.0 for i in 1:N-1]))
Ay = copy(Ax)
Ax[2,1] = 2.0
Ax[end-1,end] = 2.0
Ay[1,2] = 2.0
Ay[end,end-1] = 2.0

function basic_version!(dr,r,p,t)
  a,α,ubar,β,D1,D2 = p
  u = r[:,:,1]
  v = r[:,:,2]
  Du = D1*(Ay*u + u*Ax)
  Dv = D2*(Ay*v + v*Ax)
  dr[:,:,1] = Du .+ a.*u.*u./v .+ ubar .- α*u
  dr[:,:,2] = Dv .+ a.*u.*u .- β*v
end

a,α,ubar,β,D1,D2 = p
uss = (ubar+β)/α
vss = (a/β)*uss^2
r0 = zeros(100,100,2)
r0[:,:,1] .= uss.+0.1.*rand.()
r0[:,:,2] .= vss

prob = ODEProblem(basic_version!,r0,(0.0,0.1),p)</code></pre><p>In this version we have encoded our initial condition to be a 3-dimensional array, with <code>u[:,:,1]</code> being the <code>A</code> part and <code>u[:,:,2]</code> being the <code>B</code> part.</p><pre><code class="language-julia hljs">@benchmark solve(prob,Tsit5())

BenchmarkTools.Trial: 48 samples with 1 evaluation.
 Range (min … max):   96.001 ms … 130.443 ms  ┊ GC (min … max):  7.04% … 16.06%
 Time  (median):     104.225 ms               ┊ GC (median):    10.48%
 Time  (mean ± σ):   105.063 ms ±   6.812 ms  ┊ GC (mean ± σ):   9.42% ±  2.62%

  ▃█▃   █▃█    ▃██   ▃█ ▃▃           ▃
  ███▇▁▇███▇▇▁▇███▁▇▁██▇██▇▁▁▇▇▇▁▇▁▁▁█▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇ ▁
  96 ms            Histogram: frequency by time          130 ms &lt;

 Memory estimate: 186.83 MiB, allocs estimate: 7341.</code></pre><p>While this version isn&#39;t very efficient,</p><h4 id="We-recommend-writing-the-&quot;high-level&quot;-code-first,-and-iteratively-optimizing-it!"><a class="docs-heading-anchor" href="#We-recommend-writing-the-&quot;high-level&quot;-code-first,-and-iteratively-optimizing-it!">We recommend writing the &quot;high-level&quot; code first, and iteratively optimizing it!</a><a id="We-recommend-writing-the-&quot;high-level&quot;-code-first,-and-iteratively-optimizing-it!-1"></a><a class="docs-heading-anchor-permalink" href="#We-recommend-writing-the-&quot;high-level&quot;-code-first,-and-iteratively-optimizing-it!" title="Permalink"></a></h4><p>The first thing that we can do is get rid of the slicing allocations. The operation <code>r[:,:,1]</code> creates a temporary array instead of a &quot;view&quot;, i.e. a pointer to the already existing memory. To make it a view, add <code>@view</code>. Note that we have to be careful with views because they point to the same memory, and thus changing a view changes the original values:</p><pre><code class="language-julia hljs">A = rand(4)
@show A
B = @view A[1:3]
B[2] = 2
@show A</code></pre><p>Notice that changing <code>B</code> changed <code>A</code>. This is something to be careful of, but at the same time we want to use this since we want to modify the output <code>dr</code>. Additionally, the last statement is a purely element-wise operation, and thus we can make use of broadcast fusion there. Let&#39;s rewrite <code>basic_version!</code> to ***avoid slicing allocations*** and to ***use broadcast fusion***:</p><pre><code class="language-julia hljs">function gm2!(dr,r,p,t)
  a,α,ubar,β,D1,D2 = p
  u = @view r[:,:,1]
  v = @view r[:,:,2]
  du = @view dr[:,:,1]
  dv = @view dr[:,:,2]
  Du = D1*(Ay*u + u*Ax)
  Dv = D2*(Ay*v + v*Ax)
  @. du = Du + a.*u.*u./v + ubar - α*u
  @. dv = Dv + a.*u.*u - β*v
end
prob = ODEProblem(gm2!,r0,(0.0,0.1),p)
@benchmark solve(prob,Tsit5())

BenchmarkTools.Trial: 58 samples with 1 evaluation.
 Range (min … max):  80.456 ms … 106.830 ms  ┊ GC (min … max): 0.00% … 10.74%
 Time  (median):     85.858 ms               ┊ GC (median):    6.34%
 Time  (mean ± σ):   86.916 ms ±   4.214 ms  ┊ GC (mean ± σ):  6.46% ±  1.75%

              █ ▄
  ▅▃▁▁▁▁▁▁▁▆▃▆█▃██▆▆▅▃▃▅▃█▆▁▃▁▃▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃ ▁
  80.5 ms         Histogram: frequency by time          102 ms &lt;

 Memory estimate: 119.71 MiB, allocs estimate: 5871.</code></pre><p>Now, most of the allocations are taking place in <code>Du = D1*(Ay*u + u*Ax)</code> since those operations are vectorized and not mutating. We should instead replace the matrix multiplications with <code>mul!</code>. When doing so, we will need to have cache variables to write into. This looks like:</p><pre><code class="language-julia hljs">Ayu = zeros(N,N)
uAx = zeros(N,N)
Du = zeros(N,N)
Ayv = zeros(N,N)
vAx = zeros(N,N)
Dv = zeros(N,N)
function gm3!(dr,r,p,t)
  a,α,ubar,β,D1,D2 = p
  u = @view r[:,:,1]
  v = @view r[:,:,2]
  du = @view dr[:,:,1]
  dv = @view dr[:,:,2]
  mul!(Ayu,Ay,u)
  mul!(uAx,u,Ax)
  mul!(Ayv,Ay,v)
  mul!(vAx,v,Ax)
  @. Du = D1*(Ayu + uAx)
  @. Dv = D2*(Ayv + vAx)
  @. du = Du + a*u*u./v + ubar - α*u
  @. dv = Dv + a*u*u - β*v
end
prob = ODEProblem(gm3!,r0,(0.0,0.1),p)
@benchmark solve(prob,Tsit5())

BenchmarkTools.Trial: 71 samples with 1 evaluation.
 Range (min … max):  66.051 ms … 78.626 ms  ┊ GC (min … max): 0.00% … 6.51%
 Time  (median):     69.778 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   70.563 ms ±  3.392 ms  ┊ GC (mean ± σ):  1.68% ± 2.94%

     ▂▆█    ▂
  ▄▁▄███▁▆▄▁█▁▁▆█▁▆▆▁▄▁▆▁▄▁▄▄▆▁▄▆▁▁▁▆▁▄▄▁▄█▆▄▁▆▄▆▁▆▁▆▆▁▁▁▁▄▁▄ ▁
  66.1 ms         Histogram: frequency by time        77.1 ms &lt;

 Memory estimate: 29.98 MiB, allocs estimate: 4695.</code></pre><p>But our temporary variables are global variables. We need to either declare the caches as <code>const</code> or localize them. We can localize them by adding them to the parameters, <code>p</code>. It&#39;s easier for the compiler to reason about local variables than global variables. ***Localizing variables helps to ensure type stability***.</p><pre><code class="language-julia hljs">p = (1.0,1.0,1.0,10.0,0.001,100.0,Ayu,uAx,Du,Ayv,vAx,Dv) # a,α,ubar,β,D1,D2
function gm4!(dr,r,p,t)
  a,α,ubar,β,D1,D2,Ayu,uAx,Du,Ayv,vAx,Dv = p
  u = @view r[:,:,1]
  v = @view r[:,:,2]
  du = @view dr[:,:,1]
  dv = @view dr[:,:,2]
  mul!(Ayu,Ay,u)
  mul!(uAx,u,Ax)
  mul!(Ayv,Ay,v)
  mul!(vAx,v,Ax)
  @. Du = D1*(Ayu + uAx)
  @. Dv = D2*(Ayv + vAx)
  @. du = Du + a*u*u./v + ubar - α*u
  @. dv = Dv + a*u*u - β*v
end
prob = ODEProblem(gm4!,r0,(0.0,0.1),p)
@benchmark solve(prob,Tsit5())

BenchmarkTools.Trial: 75 samples with 1 evaluation.
 Range (min … max):  63.820 ms … 76.176 ms  ┊ GC (min … max): 0.00% … 6.03%
 Time  (median):     66.711 ms              ┊ GC (median):    0.00%
 Time  (mean ± σ):   67.396 ms ±  3.167 ms  ┊ GC (mean ± σ):  1.55% ± 2.78%

  ▁▁█▁█▃▆         ▁ ▁        ▆         ▁
  ███████▄▁▁▄▁▇▁▄▁█▄█▁▄▇▁▄▄▄▇█▁▁▁▁▄▁▄▁▇█▁▁▁▄▁▄▄▇▁▁▁▇▁▄▁▁▁▁▁▇▇ ▁
  63.8 ms         Histogram: frequency by time          74 ms &lt;

 Memory estimate: 29.66 MiB, allocs estimate: 1020.</code></pre><p>We could then use the BLAS <code>gemmv</code> to optimize the matrix multiplications some more, but instead let&#39;s devectorize the stencil.</p><pre><code class="language-julia hljs">p = (1.0,1.0,1.0,10.0,0.001,100.0,N)
function fast_gm!(du,u,p,t)
  a,α,ubar,β,D1,D2,N = p

  @inbounds for j in 2:N-1, i in 2:N-1
    du[i,j,1] = D1*(u[i-1,j,1] + u[i+1,j,1] + u[i,j+1,1] + u[i,j-1,1] - 4u[i,j,1]) +
              a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]
  end

  @inbounds for j in 2:N-1, i in 2:N-1
    du[i,j,2] = D2*(u[i-1,j,2] + u[i+1,j,2] + u[i,j+1,2] + u[i,j-1,2] - 4u[i,j,2]) +
            a*u[i,j,1]^2 - β*u[i,j,2]
  end

  @inbounds for j in 2:N-1
    i = 1
    du[1,j,1] = D1*(2u[i+1,j,1] + u[i,j+1,1] + u[i,j-1,1] - 4u[i,j,1]) +
            a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]
  end
  @inbounds for j in 2:N-1
    i = 1
    du[1,j,2] = D2*(2u[i+1,j,2] + u[i,j+1,2] + u[i,j-1,2] - 4u[i,j,2]) +
            a*u[i,j,1]^2 - β*u[i,j,2]
  end
  @inbounds for j in 2:N-1
    i = N
    du[end,j,1] = D1*(2u[i-1,j,1] + u[i,j+1,1] + u[i,j-1,1] - 4u[i,j,1]) +
           a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]
  end
  @inbounds for j in 2:N-1
    i = N
    du[end,j,2] = D2*(2u[i-1,j,2] + u[i,j+1,2] + u[i,j-1,2] - 4u[i,j,2]) +
           a*u[i,j,1]^2 - β*u[i,j,2]
  end

  @inbounds for i in 2:N-1
    j = 1
    du[i,1,1] = D1*(u[i-1,j,1] + u[i+1,j,1] + 2u[i,j+1,1] - 4u[i,j,1]) +
              a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]
  end
  @inbounds for i in 2:N-1
    j = 1
    du[i,1,2] = D2*(u[i-1,j,2] + u[i+1,j,2] + 2u[i,j+1,2] - 4u[i,j,2]) +
              a*u[i,j,1]^2 - β*u[i,j,2]
  end
  @inbounds for i in 2:N-1
    j = N
    du[i,end,1] = D1*(u[i-1,j,1] + u[i+1,j,1] + 2u[i,j-1,1] - 4u[i,j,1]) +
             a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]
  end
  @inbounds for i in 2:N-1
    j = N
    du[i,end,2] = D2*(u[i-1,j,2] + u[i+1,j,2] + 2u[i,j-1,2] - 4u[i,j,2]) +
             a*u[i,j,1]^2 - β*u[i,j,2]
  end

  @inbounds begin
    i = 1; j = 1
    du[1,1,1] = D1*(2u[i+1,j,1] + 2u[i,j+1,1] - 4u[i,j,1]) +
              a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]
    du[1,1,2] = D2*(2u[i+1,j,2] + 2u[i,j+1,2] - 4u[i,j,2]) +
              a*u[i,j,1]^2 - β*u[i,j,2]

    i = 1; j = N
    du[1,N,1] = D1*(2u[i+1,j,1] + 2u[i,j-1,1] - 4u[i,j,1]) +
             a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]
    du[1,N,2] = D2*(2u[i+1,j,2] + 2u[i,j-1,2] - 4u[i,j,2]) +
             a*u[i,j,1]^2 - β*u[i,j,2]

    i = N; j = 1
    du[N,1,1] = D1*(2u[i-1,j,1] + 2u[i,j+1,1] - 4u[i,j,1]) +
             a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]
    du[N,1,2] = D2*(2u[i-1,j,2] + 2u[i,j+1,2] - 4u[i,j,2]) +
             a*u[i,j,1]^2 - β*u[i,j,2]

    i = N; j = N
    du[end,end,1] = D1*(2u[i-1,j,1] + 2u[i,j-1,1] - 4u[i,j,1]) +
             a*u[i,j,1]^2/u[i,j,2] + ubar - α*u[i,j,1]
    du[end,end,2] = D2*(2u[i-1,j,2] + 2u[i,j-1,2] - 4u[i,j,2]) +
             a*u[i,j,1]^2 - β*u[i,j,2]
   end
end
prob = ODEProblem(fast_gm!,r0,(0.0,0.1),p)
@benchmark solve(prob,Tsit5())

BenchmarkTools.Trial: 700 samples with 1 evaluation.
 Range (min … max):  5.433 ms … 26.007 ms  ┊ GC (min … max):  0.00% … 56.34%
 Time  (median):     5.878 ms              ┊ GC (median):     0.00%
 Time  (mean ± σ):   7.138 ms ±  2.348 ms  ┊ GC (mean ± σ):  11.10% ± 13.88%

  ▄▇█▆▃       ▁           ▁▁▁      ▁ ▁▁▂
  ██████▆▆█▇▇▆███▇▆▆▄▆█▇█▇███▇▆▄█▇██████▆██▇▆▁▄▁▁▁▄▄▁▁▁▁▁▁▁▄ █
  5.43 ms      Histogram: log(frequency) by time     13.4 ms &lt;

 Memory estimate: 29.62 MiB, allocs estimate: 432.</code></pre><p>Notice that in this case fusing the loops and avoiding the linear operators is a major improvement of about 10x! That&#39;s an order of magnitude faster than our original MATLAB/SciPy/R vectorized style code!</p><p>Since this is tedious to do by hand, we note that <a href="https://mtk.sciml.ai/dev/">ModelingToolkit.jl&#39;s symbolic code generation</a> can do this automatically from the basic version:</p><pre><code class="language-julia hljs">function basic_version!(dr,r,p,t)
  a,α,ubar,β,D1,D2 = p
  u = r[:,:,1]
  v = r[:,:,2]
  Du = D1*(Ay*u + u*Ax)
  Dv = D2*(Ay*v + v*Ax)
  dr[:,:,1] = Du .+ a.*u.*u./v .+ ubar .- α*u
  dr[:,:,2] = Dv .+ a.*u.*u .- β*v
end

a,α,ubar,β,D1,D2 = p
uss = (ubar+β)/α
vss = (a/β)*uss^2
r0 = zeros(100,100,2)
r0[:,:,1] .= uss.+0.1.*rand.()
r0[:,:,2] .= vss

prob = ODEProblem(basic_version!,r0,(0.0,0.1),p)
de = modelingtoolkitize(prob)

# Note jac=true,sparse=true makes it automatically build sparse Jacobian code
# as well!

fastprob = ODEProblem(de,[],(0.0,0.1),jac=true,sparse=true)</code></pre><p>Lastly, we can do other things like multithread the main loops. <a href="https://github.com/JuliaSIMD/LoopVectorization.jl">LoopVectorization.jl</a> provides the <code>@turbo</code> macro for doing a lot of SIMD enhancements, and <code>@tturbo</code> is the multithreaded version.</p><h3 id="Optimizing-Algorithm-Choices"><a class="docs-heading-anchor" href="#Optimizing-Algorithm-Choices">Optimizing Algorithm Choices</a><a id="Optimizing-Algorithm-Choices-1"></a><a class="docs-heading-anchor-permalink" href="#Optimizing-Algorithm-Choices" title="Permalink"></a></h3><p>The last thing to do is then ***optimize our algorithm choice***. We have been using <code>Tsit5()</code> as our test algorithm, but in reality this problem is a stiff PDE discretization and thus one recommendation is to use <code>CVODE_BDF()</code>. However, instead of using the default dense Jacobian, we should make use of the sparse Jacobian afforded by the problem. The Jacobian is the matrix <span>$\frac{df_i}{dr_j}$</span>, where <span>$r$</span> is read by the linear index (i.e. down columns). But since the <span>$u$</span> variables depend on the <span>$v$</span>, the band size here is large, and thus this will not do well with a Banded Jacobian solver. Instead, we utilize sparse Jacobian algorithms. <code>CVODE_BDF</code> allows us to use a sparse Newton-Krylov solver by setting <code>linear_solver = :GMRES</code>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The <a href="../advanced_ode_example/#stiff">Solving Large Stiff Equations</a> tutorial goes through these details. This is simply to give a taste of how much optimization opportunity is left on the table!</p></div></div><p>Let&#39;s see how our fast right-hand side scales as we increase the integration time.</p><pre><code class="language-julia hljs">prob = ODEProblem(fast_gm!,r0,(0.0,10.0),p)
@benchmark solve(prob,Tsit5())

BenchmarkTools.Trial: 3 samples with 1 evaluation.
 Range (min … max):  1.578 s …    2.502 s  ┊ GC (min … max): 31.99% … 58.83%
 Time  (median):     1.580 s               ┊ GC (median):    35.16%
 Time  (mean ± σ):   1.887 s ± 532.716 ms  ┊ GC (mean ± σ):  44.74% ± 14.66%

  █                                                        ▁
  █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█ ▁
  1.58 s         Histogram: frequency by time          2.5 s &lt;

 Memory estimate: 2.76 GiB, allocs estimate: 39323.</code></pre><pre><code class="language-julia hljs">using Sundials
@benchmark solve(prob,CVODE_BDF(linear_solver=:GMRES))

BenchmarkTools.Trial: 11 samples with 1 evaluation.
 Range (min … max):  450.051 ms … 476.904 ms  ┊ GC (min … max): 0.00% … 0.38%
 Time  (median):     460.246 ms               ┊ GC (median):    0.75%
 Time  (mean ± σ):   461.439 ms ±   9.264 ms  ┊ GC (mean ± σ):  0.56% ± 0.33%

  █    █   █  █ █        █ ██                        █   █    █
  █▁▁▁▁█▁▁▁█▁▁█▁█▁▁▁▁▁▁▁▁█▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁█▁▁▁▁█ ▁
  450 ms           Histogram: frequency by time          477 ms &lt;

 Memory estimate: 120.93 MiB, allocs estimate: 20000.</code></pre><pre><code class="language-julia hljs">prob = ODEProblem(fast_gm!,r0,(0.0,100.0),p)
# Will go out of memory if we don&#39;t turn off `save_everystep`!
@benchmark solve(prob,Tsit5(),save_everystep=false)

BenchmarkTools.Trial: 2 samples with 1 evaluation.
 Range (min … max):  3.075 s …   3.095 s  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     3.085 s              ┊ GC (median):    0.00%
 Time  (mean ± σ):   3.085 s ± 14.570 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%

  █                                                       █
  █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█ ▁
  3.07 s         Histogram: frequency by time         3.1 s &lt;

 Memory estimate: 2.90 MiB, allocs estimate: 60.</code></pre><pre><code class="language-julia hljs">@benchmark solve(prob,CVODE_BDF(linear_solver=:GMRES),save_everystep=false)

BenchmarkTools.Trial: 4 samples with 1 evaluation.
 Range (min … max):  1.342 s …   1.386 s  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     1.352 s              ┊ GC (median):    0.00%
 Time  (mean ± σ):   1.358 s ± 19.636 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%

  █    █               █                                  █
  █▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█ ▁
  1.34 s         Histogram: frequency by time        1.39 s &lt;

 Memory estimate: 3.09 MiB, allocs estimate: 49880.</code></pre><pre><code class="language-julia hljs">prob = ODEProblem(fast_gm!,r0,(0.0,500.0),p)
@benchmark solve(prob,CVODE_BDF(linear_solver=:GMRES),save_everystep=false)

BenchmarkTools.Trial: 3 samples with 1 evaluation.
 Range (min … max):  1.817 s …   1.915 s  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     1.825 s              ┊ GC (median):    0.00%
 Time  (mean ± σ):   1.853 s ± 54.179 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%

  █   █                                                   █
  █▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█ ▁
  1.82 s         Histogram: frequency by time        1.91 s &lt;

 Memory estimate: 3.83 MiB, allocs estimate: 66931.</code></pre><p>Notice that we&#39;ve eliminated almost all allocations, allowing the code to grow without hitting garbage collection and slowing down.</p><p>Why is <code>CVODE_BDF</code> doing well? What&#39;s happening is that, because the problem is stiff, the number of steps required by the explicit Runge-Kutta method grows rapidly, whereas <code>CVODE_BDF</code> is taking large steps. Additionally, the <code>GMRES</code> linear solver form is quite an efficient way to solve the implicit system in this case. This is problem-dependent, and in many cases using a Krylov method effectively requires a preconditioner, so you need to play around with testing other algorithms and linear solvers to find out what works best with your problem.</p><p>Now continue to the <a href="../advanced_ode_example/#stiff">Solving Large Stiff Equations</a> tutorial for more details on optimizing the algorithm choice for such codes.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../ode_example/">« Ordinary Differential Equations</a><a class="docs-footer-nextpage" href="../advanced_ode_example/">Solving Large Stiff Equations »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Sunday 9 October 2022 18:26">Sunday 9 October 2022</span>. Using Julia version 1.8.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
