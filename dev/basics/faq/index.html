<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Frequently Asked Questions · DifferentialEquations.jl</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-90474609-3', 'auto');
ga('send', 'pageview');
</script><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><nav class="toc"><a href="../../"><img class="logo" src="../../assets/logo.png" alt="DifferentialEquations.jl logo"/></a><h1>DifferentialEquations.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">Tutorials</span><ul><li><a class="toctext" href="../../tutorials/ode_example/">Ordinary Differential Equations</a></li><li><a class="toctext" href="../../tutorials/advanced_ode_example/">Solving Stiff Equations</a></li><li><a class="toctext" href="../../tutorials/sde_example/">Stochastic Differential Equations</a></li><li><a class="toctext" href="../../tutorials/rode_example/">Random Ordinary Differential Equations</a></li><li><a class="toctext" href="../../tutorials/dde_example/">Delay Differential Equations</a></li><li><a class="toctext" href="../../tutorials/dae_example/">Differential Algebraic Equations</a></li><li><a class="toctext" href="../../tutorials/discrete_stochastic_example/">Discrete Stochastic (Gillespie) Equations</a></li><li><a class="toctext" href="../../tutorials/jump_diffusion/">Jump Diffusion Equations</a></li><li><a class="toctext" href="../../tutorials/bvp_example/">Boundary Value Problems</a></li><li><a class="toctext" href="../../tutorials/additional/">Additional Tutorials</a></li></ul></li><li><span class="toctext">Basics</span><ul><li><a class="toctext" href="../overview/">Overview of DifferentialEquations.jl</a></li><li><a class="toctext" href="../common_solver_opts/">Common Solver Options</a></li><li><a class="toctext" href="../solution/">Solution Handling</a></li><li><a class="toctext" href="../plot/">Plot Functions</a></li><li><a class="toctext" href="../integrator/">Integrator Interface</a></li><li><a class="toctext" href="../problem/">Problem Interface</a></li><li class="current"><a class="toctext" href>Frequently Asked Questions</a><ul class="internal"><li><a class="toctext" href="#Performance-1">Performance</a></li><li><a class="toctext" href="#Complicated-Models-1">Complicated Models</a></li><li><a class="toctext" href="#Numerical-Error-1">Numerical Error</a></li><li><a class="toctext" href="#Autodifferentiation-and-Dual-Numbers-1">Autodifferentiation and Dual Numbers</a></li></ul></li><li><a class="toctext" href="../compatibility_chart/">Solver Compatibility Chart</a></li></ul></li><li><span class="toctext">Problem Types</span><ul><li><a class="toctext" href="../../types/discrete_types/">Discrete Problems</a></li><li><a class="toctext" href="../../types/ode_types/">ODE Problems</a></li><li><a class="toctext" href="../../types/dynamical_types/">Dynamical, Hamiltonian and 2nd Order ODE Problems</a></li><li><a class="toctext" href="../../types/split_ode_types/">Split ODE Problems</a></li><li><a class="toctext" href="../../types/steady_state_types/">Steady State Problems</a></li><li><a class="toctext" href="../../types/bvp_types/">BVP Problems</a></li><li><a class="toctext" href="../../types/sde_types/">SDE Problems</a></li><li><a class="toctext" href="../../types/rode_types/">RODE Problems</a></li><li><a class="toctext" href="../../types/dde_types/">DDE Problems</a></li><li><a class="toctext" href="../../types/dae_types/">DAE Problems</a></li><li><a class="toctext" href="../../types/jump_types/">Jump Problems</a></li></ul></li><li><span class="toctext">Solver Algorithms</span><ul><li><a class="toctext" href="../../solvers/discrete_solve/">Discrete Solvers</a></li><li><a class="toctext" href="../../solvers/ode_solve/">ODE Solvers</a></li><li><a class="toctext" href="../../solvers/dynamical_solve/">Dynamical, Hamiltonian, and 2nd Order ODE Solvers</a></li><li><a class="toctext" href="../../solvers/split_ode_solve/">Split ODE Solvers</a></li><li><a class="toctext" href="../../solvers/steady_state_solve/">Steady State Solvers</a></li><li><a class="toctext" href="../../solvers/bvp_solve/">BVP Solvers</a></li><li><a class="toctext" href="../../solvers/jump_solve/">Jump Problem Solvers</a></li><li><a class="toctext" href="../../solvers/sde_solve/">SDE Solvers</a></li><li><a class="toctext" href="../../solvers/rode_solve/">RODE Solvers</a></li><li><a class="toctext" href="../../solvers/dde_solve/">DDE Solvers</a></li><li><a class="toctext" href="../../solvers/dae_solve/">DAE Solvers</a></li><li><a class="toctext" href="../../solvers/benchmarks/">Solver Benchmarks</a></li></ul></li><li><span class="toctext">Additional Features</span><ul><li><a class="toctext" href="../../features/performance_overloads/">DiffEqFunctions (Jacobians, Gradients, etc.) and Jacobian Types</a></li><li><a class="toctext" href="../../features/diffeq_arrays/">DiffEq-Specific Array Types</a></li><li><a class="toctext" href="../../features/diffeq_operator/">DiffEqOperators</a></li><li><a class="toctext" href="../../features/noise_process/">Noise Processes</a></li><li><a class="toctext" href="../../features/linear_nonlinear/">Specifying (Non)Linear Solvers</a></li><li><a class="toctext" href="../../features/callback_functions/">Event Handling and Callback Functions</a></li><li><a class="toctext" href="../../features/callback_library/">Callback Library</a></li><li><a class="toctext" href="../../features/ensemble/">Parallel Ensemble Simulations</a></li><li><a class="toctext" href="../../features/io/">I/O: Saving and Loading Solution Data</a></li><li><a class="toctext" href="../../features/low_dep/">Low Dependency Usage</a></li><li><a class="toctext" href="../../features/progress_bar/">Juno Progress Bar Integration</a></li></ul></li><li><span class="toctext">Analysis Tools</span><ul><li><a class="toctext" href="../../analysis/parameterized_functions/">ParameterizedFunctions</a></li><li><a class="toctext" href="../../analysis/parameter_estimation/">Parameter Estimation and Bayesian Analysis</a></li><li><a class="toctext" href="../../analysis/bifurcation/">Bifurcation Analysis</a></li><li><a class="toctext" href="../../analysis/sensitivity/">Local Sensitivity Analysis (Automatic Differentiation)</a></li><li><a class="toctext" href="../../analysis/global_sensitivity/">Global Sensitivity Analysis</a></li><li><a class="toctext" href="../../analysis/uncertainty_quantification/">Uncertainty Quantification</a></li><li><a class="toctext" href="../../analysis/neural_networks/">Neural Networks</a></li><li><a class="toctext" href="../../analysis/dev_and_test/">Algorithm Development and Testing</a></li></ul></li><li><span class="toctext">Domain Modeling Tools</span><ul><li><a class="toctext" href="../../models/multiscale/">Multi-Scale Models</a></li><li><a class="toctext" href="../../models/physical/">Physical Models</a></li><li><a class="toctext" href="../../models/financial/">Financial Models</a></li><li><a class="toctext" href="../../models/biological/">Chemical Reaction Models</a></li><li><a class="toctext" href="../../models/external_modeling/">External Modeling Packages</a></li></ul></li><li><span class="toctext">APIs</span><ul><li><span class="toctext">DiffEqBase API</span><ul><li><a class="toctext" href="../../apis/diffeqbase/overview/">Overview</a></li><li><a class="toctext" href="../../apis/diffeqbase/functions/">DE functions</a></li><li><a class="toctext" href="../../apis/diffeqbase/problems/">Problems</a></li><li><a class="toctext" href="../../apis/diffeqbase/solutions/">Solutions</a></li><li><a class="toctext" href="../../apis/diffeqbase/solvers/">Solvers</a></li><li><a class="toctext" href="../../apis/diffeqbase/de_types/">DE types</a></li><li><a class="toctext" href="../../apis/diffeqbase/operators/">Operators</a></li><li><a class="toctext" href="../../apis/diffeqbase/callbacks/">Callbacks</a></li><li><a class="toctext" href="../../apis/diffeqbase/interpolation/">Interpolation</a></li><li><a class="toctext" href="../../apis/diffeqbase/ensembles/">Ensembles</a></li><li><a class="toctext" href="../../apis/diffeqbase/data_arrays/">Data arrays</a></li><li><a class="toctext" href="../../apis/diffeqbase/noise/">Noise processes</a></li><li><a class="toctext" href="../../apis/diffeqbase/utility/">Utility</a></li></ul></li><li><a class="toctext" href="../../apis/diffeqbio/">DiffEqBiological.jl API</a></li></ul></li><li><span class="toctext">Extra Details</span><ul><li><a class="toctext" href="../../extras/timestepping/">Timestepping Method Descriptions</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Basics</li><li><a href>Frequently Asked Questions</a></li></ul><a class="edit-page" href="https://github.com/JuliaDiffEq/DiffEqDocs.jl/blob/master/docs/src/basics/faq.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Frequently Asked Questions</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Frequently-Asked-Questions-1" href="#Frequently-Asked-Questions-1">Frequently Asked Questions</a></h1><p>This page is a compilation of frequently asked questions and answers.</p><h2><a class="nav-anchor" id="Performance-1" href="#Performance-1">Performance</a></h2><h4><a class="nav-anchor" id="Do-you-support-GPUs?-Multithreading?-Distributed-computation?-1" href="#Do-you-support-GPUs?-Multithreading?-Distributed-computation?-1">Do you support GPUs? Multithreading? Distributed computation?</a></h4><p>Yes. The <code>*</code>DiffEq.jl libraries (OrdinaryDiffEq.jl, StochasticDiffEq.jl, and DelayDiffEq.jl) are all written to be generic to the array and number types. This means they will adopt the implementation that is given by the array type. The in-place algorithms internally utilize Julia&#39;s broadcast (with some exceptions due to a Julia bug for now, see <a href="https://github.com/JuliaDiffEq/OrdinaryDiffEq.jl/issues/106">this issue</a>) and Julia&#39;s <code>mul!</code> in-place matrix multiplication function. The out-of-place algorithms utilize standard arithmetical functions. Both additionally utilize the user&#39;s norm specified via the common interface options and, if a stiff solver, ForwardDiff/DiffEqDiffTools for the Jacobian calculation, and Base linear factorizations for the linear solve. For your type, you may likely need to give a <a href="http://docs.juliadiffeq.org/latest/basics/common_solver_opts.html#Advanced-Adaptive-Stepsize-Control-1">better form of the norm</a>, <a href="http://docs.juliadiffeq.org/latest/features/performance_overloads.html">Jacobian</a>, or <a href="http://docs.juliadiffeq.org/latest/features/linear_nonlinear.html">linear solve calculations</a> to fully utilize parallelism.</p><p>GPUArrays.jl (CuArrays.jl), ArrayFire.jl, DistributedArrays.jl have been tested and work in various forms, where the last one is still not recommended for common use yet.</p><p>The next question is whether it matters. Generally, your system has to be large for parallelism to matter. Using a multithreaded array for broadcast we find helpful around <code>N&gt;1000</code>, though the Sundials manual says <code>N&gt;100,000</code>. For high order Runge-Kutta methods it&#39;s likely lower than the Sundials estimate because of more operations packed into each internal step, but as always that will need more benchmarks to be precise and will depend on the problem being solved. GPUs generally require some intensive parallel operation in the user&#39;s <code>f</code> function to be viable, for example a matrix multiplication for a stencil computation in a PDE. If you&#39;re simply solving some ODE element-wise on a big array it likely won&#39;t do much or it will slow things down just due to how GPUs work. DistributedArrays require parallel linear solves to really matter, and thus are only recommended when you have a problem that cannot fit into memory or are using a stiff solver with a Krylov method for the linear solves.</p><h4><a class="nav-anchor" id="My-ODE-is-solving-really-slow...-what-do-I-do?-1" href="#My-ODE-is-solving-really-slow...-what-do-I-do?-1">My ODE is solving really slow... what do I do?</a></h4><p>First, check for bugs. These solvers go through a ton of convergence tests and so if there&#39;s a solver issue, it&#39;s either just something to do with how numerical methods work or it&#39;s a user-error (generally the latter, though check the later part of the FAQ on normal numerical errors). User-errors in the <code>f</code> function causing a divergence of the solution is the most common reason for reported slow codes.</p><p>If you have no bugs, great! The standard tricks for optimizing Julia code then apply. What you want to do first is make sure your function does not allocate. If your system is small (<code>&lt;=100</code> ODEs/SDEs/DDEs/DAEs?), then you should set your system up to use <a href="https://github.com/JuliaArrays/StaticArrays.jl">StaticArrays.jl</a>. This is demonstrated <a href="http://docs.juliadiffeq.org/latest/tutorials/ode_example.html#Example-3:-Using-Other-Types-for-Systems-of-Equations-1">in the ODE tutorial</a> with static matrices. Static vectors/arrays are stack-allocated, and thus creating new arrays is free and the compiler doesn&#39;t have to heap-allocate any of the temporaries (that&#39;s the expensive part!). These have specialized super fast dispatches for arithmetic operations and extra things like LU-factorizations, and thus they are preferred when possible. However, they lose efficiency if they grow too large.</p><p>For anything larger, you should use the <code>in-place</code> syntax <code>f(du,u,p,t)</code> and make sure that your function doesn&#39;t allocate. Assuming you know of a <code>u0</code>, you should be able to do:</p><pre><code class="language-julia">du = similar(u0)
@time f(du,u0,p,t)</code></pre><p>and see close to zero allocations and close to zero memory allocated. If you see more, then you might have a type-instability or have temporary arrays. To find type-instabilities, you should do:</p><pre><code class="language-julia">@code_warntype f(du,u,p,t)</code></pre><p>and read the printout to see if there&#39;s any types that aren&#39;t inferred by the compiler, and fix them. If you have any global variables, you should make them <code>const</code>. As for allocations, some common things that allocate are:</p><ul><li>Array slicing, like <code>u[1:5]</code>. Instead, use <code>@view u[1:5]</code></li><li>Matrix multiplication with <code>*</code>. Instead of <code>A*b</code>, use <code>A_mul_B!(c,A,b)</code> for some pre-allocated cache vector <code>c</code>.</li><li>Non-broadcasted expressions. Every expression on arrays should <code>.=</code> into another array, or it should be re-written to loop and do computations with scalar (or static array) values.</li></ul><p>For an example of optimizing a function resulting from a PDE discretization, see <a href="http://www.stochasticlifestyle.com/solving-systems-stochastic-pdes-using-gpus-julia/">this blog post</a>.</p><h4><a class="nav-anchor" id="The-stiff-solver-takes-forever-to-take-steps-for-my-PDE-discretization!-Why?-1" href="#The-stiff-solver-takes-forever-to-take-steps-for-my-PDE-discretization!-Why?-1">The stiff solver takes forever to take steps for my PDE discretization! Why?</a></h4><p>The solvers for stiff solvers require solving a nonlinear equation each step. In order to do so, they have to do a few Newton steps. By default, these methods assume that the Jacobian is dense, automatically calculate the Jacobian for you, and do a dense factorization. However, in many cases you may want to use alternatives that are more tuned for your problem.</p><p>First of all, when available, it&#39;s recommended that you pass a function for computing your Jacobian. This is discussed in the <a href="http://docs.juliadiffeq.org/latest/features/performance_overloads.html#Declaring-Explicit-Jacobians-1">performance overloads</a> section. Jacobians are especially helpful for Rosenbrock methods.</p><p>Secondly, if your Jacobian isn&#39;t dense, you shouldn&#39;t use a dense Jacobian! In the Sundials algorithm you can set <code>linear_solver=:Band</code> for banded Jacobians for example. More support is coming for this soon.</p><p>But lastly, you shouldn&#39;t use a dense factorization for large sparse matrices. Instead, if you&#39;re using  a <code>*DiffEq</code> library you should <a href="http://docs.juliadiffeq.org/latest/features/linear_nonlinear.html">specify a linear solver</a>. For Sundials.jl, you should change the <code>linear_solver</code> option. See <a href="http://docs.juliadiffeq.org/latest/solvers/ode_solve.html#Sundials.jl-1">the ODE solve Sundials portion</a> for details on that. Right now, Sundials.jl is the recommended method for stiff problems with large sparse Jacobians. <code>linear_solver=:Band</code> should be used if your Jacobian is banded and you can specify the band sizes. If you only know the Jacobian is sparse, <code>linear_solver=:GMRES</code> is a good option. Once again, a good reference for how to handle PDE discretizations can be found <a href="http://www.stochasticlifestyle.com/solving-systems-stochastic-pdes-using-gpus-julia/">at this blog post</a>.</p><h4><a class="nav-anchor" id="My-Problem-Has-Discontinuities-and-is-Unstable-/-Slow,-What-Do-I-Do?-1" href="#My-Problem-Has-Discontinuities-and-is-Unstable-/-Slow,-What-Do-I-Do?-1">My Problem Has Discontinuities and is Unstable / Slow, What Do I Do?</a></h4><p><a href="https://discourse.julialang.org/t/handling-instability-when-solving-ode-problems/9019/5">This Discourse post</a> goes into detail for how to handle discontinuities in your ODE function and how to use that extra information to speed up the solver.</p><h2><a class="nav-anchor" id="Complicated-Models-1" href="#Complicated-Models-1">Complicated Models</a></h2><h4><a class="nav-anchor" id="Can-I-switch-my-ODE-function-in-the-middle-of-integration?-1" href="#Can-I-switch-my-ODE-function-in-the-middle-of-integration?-1">Can I switch my ODE function in the middle of integration?</a></h4><p>There are a few ways to do this. The simplest way is to just have a parameter to switch between the two. For example:</p><pre><code class="language-julia">function f(du,u,p,t)
  if p == 0
    du[1] = 2u[1]
  else
    du[1] = -2u[1]
  end
  du[2] = -u[2]
end</code></pre><p>Then in a callback you can make the <code>affect!</code> function modify <code>integrator.prob.p</code>. For example, we can make it change when <code>u[2]&lt;0.5</code> via:</p><pre><code class="language-julia">condition(t,u,integrator) = u[2] - 0.5
affect!(integrator) = integrator.prob.p = 1</code></pre><p>Then it will change betweeen the two ODE choices for <code>du1</code> at that moment. Another way to do this is to make the ODE functions all be the same type via FunctionWrappers.jl, but that is unnecessary. With the way that modern processors work, there exists branch prediction and thus execution of a conditional is free if it&#39;s predictable which branch will be taken. In this case, almost every call to <code>f</code> takes the <code>p==0</code> route until the callback, at which point it is almost always the <code>else</code> route. Therefore the processor will effectively get rid of the computational cost associated with this, so you&#39;re likely over-optimizing if you&#39;re going further (unless this change happens every step, but even then this is probably the cheapest part of the computation...).</p><h2><a class="nav-anchor" id="Numerical-Error-1" href="#Numerical-Error-1">Numerical Error</a></h2><h4><a class="nav-anchor" id="The-solver-doesn&#39;t-obey-physical-law-X-(e.g.-conservation-of-energy)-1" href="#The-solver-doesn&#39;t-obey-physical-law-X-(e.g.-conservation-of-energy)-1">The solver doesn&#39;t obey physical law X (e.g. conservation of energy)</a></h4><p>Yes, this is because the numerical solution of the ODE is not the exact solution. There are a few ways that you can handle this problem. One way is to get a more exact solution. Thus instead of</p><pre><code class="language-julia">sol = solve(prob,alg)</code></pre><p>use</p><pre><code class="language-julia">sol = solve(prob,alg,abstol=1e-10,reltol=1e-10)</code></pre><p>Of course, there&#39;s always a tradeoff between accuracy and efficiency, so play around to find out what&#39;s right for your problem.</p><p>Another thing you can do is use a callback. There are some <a href="http://docs.juliadiffeq.org/latest/features/callback_library.html">premade callbacks in the callback library</a> which handle these sorts of things like projecting to manifolds and preserving positivity.</p><h5><a class="nav-anchor" id="The-symplectic-integrator-doesn&#39;t-conserve-energy?-1" href="#The-symplectic-integrator-doesn&#39;t-conserve-energy?-1">The symplectic integrator doesn&#39;t conserve energy?</a></h5><p>Yes, symplectic integrators do not exactly conserve energy. It is a common misconception that they do. What symplectic integrators actually do is solve for a trajectory which rests on a symplectic manifold that is perturbed from the true solution&#39;s manifold by the truncation error. This means that symplectic integrators do not experience (very much) long time drift, but their orbit is not exactly the same as the true solution in phase space and thus you will see differences in energy that tend to look periodic. There is a small drift which grows linearly and is related to floating point error, but this drift is much less than standard methods. This is why symplectic methods are recommended for long time integration.</p><p>For conserving energy, there are a few things you can do. First of all, the energy error is related to the integration error, so simply solving with higher accuracy will reduce the error. The results in the <a href="https://github.com/JuliaDiffEq/DiffEqBenchmarks.jl">DiffEqBenchmarks</a> show that using a <code>DPRKN</code> method with low tolerance can be a great choice. Another thing you can do is use <a href="http://docs.juliadiffeq.org/latest/features/callback_library.html">the ManifoldProjection callback from the callback library</a>.</p><h4><a class="nav-anchor" id="How-do-I-get-to-zero-error?-1" href="#How-do-I-get-to-zero-error?-1">How do I get to zero error?</a></h4><p>You can&#39;t. For floating point numbers, you shouldn&#39;t use below <code>abstol=1e-14</code> and <code>reltol=1e-14</code>. If you need lower than that, use arbitrary precision numbers like BigFloats or <a href="https://github.com/JuliaArbTypes/ArbFloats.jl">ArbFloats.jl</a>.</p><h2><a class="nav-anchor" id="Autodifferentiation-and-Dual-Numbers-1" href="#Autodifferentiation-and-Dual-Numbers-1">Autodifferentiation and Dual Numbers</a></h2><h4><a class="nav-anchor" id="Are-the-native-Julia-solvers-compatible-with-autodifferentiation?-1" href="#Are-the-native-Julia-solvers-compatible-with-autodifferentiation?-1">Are the native Julia solvers compatible with autodifferentiation?</a></h4><p>Yes! Take a look at the <a href="http://docs.juliadiffeq.org/latest/analysis/sensitivity.html">sensitivity analysis</a> page for more details.</p><p>If the algorithm does not have differentiation of parameter-depedendent events, then you simply need to make the initial condition have elements of Dual numbers. If the algorithm uses Dual numbers, you need to make sure that time is also given by Dual numbers.</p><p>To show this in action, let&#39;s say we want to find the Jacobian of solution of the Lotka-Volterra equation at <code>t=10</code> with respect to the parameters.</p><pre><code class="language-julia">function func(du,u,p,t)
  du[1] = p[1] * u[1] - p[2] * u[1]*u[2]
  du[2] = -3 * u[2] + u[1]*u[2]
end
function f(p)
  prob = ODEProblem(func,eltype(p).([1.0,1.0]),(0.0,10.0),p)
  # Lower tolerances to show the methods converge to the same value
  solve(prob,Tsit5(),save_everystep=false,abstol=1e-12,reltol=1e-12)[end]
end</code></pre><p>This function takes in new parameters and spits out the solution at the end. We make the inital condition <code>eltype(p).([1.0,1.0])</code> so that way it&#39;s typed to be Dual numbers whenever <code>p</code> is an array of <code>Dual</code> numbers, and we do the same for the timespan just to show what you&#39;d do if there was parameters-dependent events. Then we can take the Jacobian via ForwardDiff.jl:</p><pre><code class="language-julia">using ForwardDiff
ForwardDiff.jacobian(f,[1.5,1.0])

2×2 Array{Float64,2}:
  2.16056   0.188569
 -6.25677  -0.697978</code></pre><p>and compare it to Calculus.jl:</p><pre><code class="language-julia">Calculus.jacobian(f,[1.5,1.0],:central)

2×2 Array{Float64,2}:
  2.16056   0.188569
 -6.25677  -0.697978</code></pre><h4><a class="nav-anchor" id="I-get-Dual-number-errors-when-I-solve-my-ODE-with-Rosenbrock-or-SDIRK-methods...?-1" href="#I-get-Dual-number-errors-when-I-solve-my-ODE-with-Rosenbrock-or-SDIRK-methods...?-1">I get Dual number errors when I solve my ODE with Rosenbrock or SDIRK methods...?</a></h4><p>This is because you&#39;re using a cache which is not compatible with autodifferentiaion via ForwardDiff.jl. For example, if we use the ODE function:</p><pre><code class="language-julia">using LinearAlgebra, OrdinaryDiffEq
function foo(du, u, (A, tmp), t)
    mul!(tmp, A, u)
    @. du = u + tmp
    nothing
end
prob = ODEProblem(foo, ones(5, 5), (0., 1.0), (ones(5,5), zeros(5,5)))
solve(prob, Rosenbrock23())</code></pre><p>Here we use a cached temporary array in order to avoid the allocations of matrix multiplication. When autodifferentiation occurs, the element type of <code>u</code> is <code>Dual</code> numbers, so <code>A*u</code> produces <code>Dual</code> numbers, so the error arises when it tries to write into <code>tmp</code>. There are two ways to avoid this. The first way, the easy way, is to just turn off autodifferentiation with the <code>autodiff=false</code> option in the solver. Every solver which uses autodifferentiation has this option. Thus we&#39;d solve this with:</p><pre><code class="language-julia">prob = ODEProblem(f,rand(4),(0.0,1.0))
sol = solve(prob,Rosenbrock23(autodiff=false))</code></pre><p>and it will use a numerical differentiation fallback (DiffEqDiffTools.jl) to calculate Jacobians.</p><p>We could use <code>get_tmp</code> and <code>dualcache</code> functions from <code>DiffEqBase</code> to solve this issue, e.g.,</p><pre><code class="language-julia">using LinearAlgebra, OrdinaryDiffEq
using DiffEqBase: get_tmp, dualcache
function foo(du, u, (A, tmp), t)
    tmp = DiffEqBase.get_tmp(tmp, u)
    mul!(tmp, A, u)
    @. du = u + tmp
    nothing
end
prob = ODEProblem(foo, ones(5, 5), (0., 1.0), (ones(5,5), DiffEqBase.dualcache(zeros(5,5))))
solve(prob, TRBDF2())</code></pre><footer><hr/><a class="previous" href="../problem/"><span class="direction">Previous</span><span class="title">Problem Interface</span></a><a class="next" href="../compatibility_chart/"><span class="direction">Next</span><span class="title">Solver Compatibility Chart</span></a></footer></article></body></html>
